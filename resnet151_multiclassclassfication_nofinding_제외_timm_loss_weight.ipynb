{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/young-hyun-park/capston_design/blob/main/resnet151_multiclassclassfication_nofinding_%EC%A0%9C%EC%99%B8_timm_loss_weight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBDtfS9yrW5a"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goD9iEktoLXJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "import os\n",
        "import re\n",
        "import nibabel as nib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6wKaDSCip-E"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozBlO5WonVgP"
      },
      "outputs": [],
      "source": [
        "zip_path = sorted(glob('/content/drive/Shareddrives/캡스톤 디자인1/dataset/multiclass_clahe_512/*'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZT94Zzx-ybX"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "for path in zip_path:\n",
        "  zip_file = zipfile.ZipFile(path)\n",
        "  zip_file.extractall('/content/datasets/'+path.split('/')[-1].split('.')[0])\n",
        "  zip_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9lawTI5-z8l"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/datasets/'\n",
        "from glob import glob\n",
        "file_data = glob(PATH+'*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_uXhfOA0l3D"
      },
      "outputs": [],
      "source": [
        "image_path =list()\n",
        "for path in file_data:\n",
        "  infile_image_path = glob(path+'/*.png')\n",
        "  image_path+=infile_image_path\n",
        "image_path = sorted(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAQ9b1k300wj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f915c2-1e84-4f8e-a0b1-309f0f54cd90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55870"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MGDc7JXko4k"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkWDvp5eMhpH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df= pd.read_csv('/content/drive/Shareddrives/캡스톤 디자인1/processed_data_entry.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP3-7qRdk2ZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "95accd8e-409e-4ee5-c94f-c3b7404ca8f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
              "0      00000001_000.png            Cardiomegaly            0           1   \n",
              "1      00000001_001.png  Cardiomegaly,Emphysema            1           1   \n",
              "2      00000001_002.png   Cardiomegaly,Effusion            2           1   \n",
              "3      00000002_000.png              No Finding            0           2   \n",
              "4      00000003_001.png                  Hernia            0           3   \n",
              "...                 ...                     ...          ...         ...   \n",
              "76661  00030801_001.png          Mass,Pneumonia            1       30801   \n",
              "76662  00030802_000.png              No Finding            0       30802   \n",
              "76663  00030803_000.png              No Finding            0       30803   \n",
              "76664  00030804_000.png              No Finding            0       30804   \n",
              "76665  00030805_000.png              No Finding            0       30805   \n",
              "\n",
              "       Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
              "0               57              M            PA                 2682     2749   \n",
              "1               58              M            PA                 2894     2729   \n",
              "2               58              M            PA                 2500     2048   \n",
              "3               80              M            PA                 2500     2048   \n",
              "4               74              F            PA                 2500     2048   \n",
              "...            ...            ...           ...                  ...      ...   \n",
              "76661           38              M            PA                 2048     2500   \n",
              "76662           28              M            PA                 2048     2500   \n",
              "76663           42              F            PA                 2048     2500   \n",
              "76664           29              F            PA                 2048     2500   \n",
              "76665           26              M            PA                 2048     2500   \n",
              "\n",
              "       OriginalImagePixelSpacing[x     y]  \n",
              "0                            0.143  0.143  \n",
              "1                            0.143  0.143  \n",
              "2                            0.168  0.168  \n",
              "3                            0.171  0.171  \n",
              "4                            0.168  0.168  \n",
              "...                            ...    ...  \n",
              "76661                        0.168  0.168  \n",
              "76662                        0.168  0.168  \n",
              "76663                        0.168  0.168  \n",
              "76664                        0.168  0.168  \n",
              "76665                        0.171  0.171  \n",
              "\n",
              "[76666 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6532bd3-50dc-4805-9726-a89a8bfde1b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Finding Labels</th>\n",
              "      <th>Follow-up #</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Gender</th>\n",
              "      <th>View Position</th>\n",
              "      <th>OriginalImage[Width</th>\n",
              "      <th>Height]</th>\n",
              "      <th>OriginalImagePixelSpacing[x</th>\n",
              "      <th>y]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000001_000.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2682</td>\n",
              "      <td>2749</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00000001_001.png</td>\n",
              "      <td>Cardiomegaly,Emphysema</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2894</td>\n",
              "      <td>2729</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00000001_002.png</td>\n",
              "      <td>Cardiomegaly,Effusion</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00000002_000.png</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.171</td>\n",
              "      <td>0.171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00000003_001.png</td>\n",
              "      <td>Hernia</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>74</td>\n",
              "      <td>F</td>\n",
              "      <td>PA</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76661</th>\n",
              "      <td>00030801_001.png</td>\n",
              "      <td>Mass,Pneumonia</td>\n",
              "      <td>1</td>\n",
              "      <td>30801</td>\n",
              "      <td>38</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2048</td>\n",
              "      <td>2500</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76662</th>\n",
              "      <td>00030802_000.png</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>0</td>\n",
              "      <td>30802</td>\n",
              "      <td>28</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2048</td>\n",
              "      <td>2500</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76663</th>\n",
              "      <td>00030803_000.png</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>0</td>\n",
              "      <td>30803</td>\n",
              "      <td>42</td>\n",
              "      <td>F</td>\n",
              "      <td>PA</td>\n",
              "      <td>2048</td>\n",
              "      <td>2500</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76664</th>\n",
              "      <td>00030804_000.png</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>0</td>\n",
              "      <td>30804</td>\n",
              "      <td>29</td>\n",
              "      <td>F</td>\n",
              "      <td>PA</td>\n",
              "      <td>2048</td>\n",
              "      <td>2500</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76665</th>\n",
              "      <td>00030805_000.png</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>0</td>\n",
              "      <td>30805</td>\n",
              "      <td>26</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2048</td>\n",
              "      <td>2500</td>\n",
              "      <td>0.171</td>\n",
              "      <td>0.171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76666 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6532bd3-50dc-4805-9726-a89a8bfde1b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6532bd3-50dc-4805-9726-a89a8bfde1b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6532bd3-50dc-4805-9726-a89a8bfde1b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4Ogd1Mps1S3"
      },
      "outputs": [],
      "source": [
        "labeling_df = pd.read_csv('/content/drive/Shareddrives/캡스톤 디자인1/multi_class_path+label_nofinding_drop.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEhHjfPS7NM6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0f214bc3-e463-4913-937b-2bf22b8c1374"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Image Index      Finding Labels\n",
              "0      /content/datasets/images_01/00000001_000.png        Cardiomegaly\n",
              "1      /content/datasets/images_01/00000003_000.png              Hernia\n",
              "2      /content/datasets/images_01/00000003_001.png              Hernia\n",
              "3      /content/datasets/images_01/00000003_002.png              Hernia\n",
              "4      /content/datasets/images_01/00000003_004.png              Hernia\n",
              "...                                             ...                 ...\n",
              "30958  /content/datasets/images_12/00030780_000.png         Atelectasis\n",
              "30959  /content/datasets/images_12/00030786_000.png            Effusion\n",
              "30960  /content/datasets/images_12/00030786_006.png       Consolidation\n",
              "30961  /content/datasets/images_12/00030789_000.png        Infiltration\n",
              "30962  /content/datasets/images_12/00030795_000.png  Pleural_Thickening\n",
              "\n",
              "[30963 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f5bc93c-e873-4e3d-967e-20cea6bf42d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Finding Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/datasets/images_01/00000001_000.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/datasets/images_01/00000003_000.png</td>\n",
              "      <td>Hernia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/datasets/images_01/00000003_001.png</td>\n",
              "      <td>Hernia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/datasets/images_01/00000003_002.png</td>\n",
              "      <td>Hernia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/datasets/images_01/00000003_004.png</td>\n",
              "      <td>Hernia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30958</th>\n",
              "      <td>/content/datasets/images_12/00030780_000.png</td>\n",
              "      <td>Atelectasis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30959</th>\n",
              "      <td>/content/datasets/images_12/00030786_000.png</td>\n",
              "      <td>Effusion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30960</th>\n",
              "      <td>/content/datasets/images_12/00030786_006.png</td>\n",
              "      <td>Consolidation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30961</th>\n",
              "      <td>/content/datasets/images_12/00030789_000.png</td>\n",
              "      <td>Infiltration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30962</th>\n",
              "      <td>/content/datasets/images_12/00030795_000.png</td>\n",
              "      <td>Pleural_Thickening</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30963 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f5bc93c-e873-4e3d-967e-20cea6bf42d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f5bc93c-e873-4e3d-967e-20cea6bf42d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f5bc93c-e873-4e3d-967e-20cea6bf42d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "labeling_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbwUcI6U1Fx3"
      },
      "outputs": [],
      "source": [
        "value_series=labeling_df['Finding Labels'].value_counts()\n",
        "value_dict = dict()\n",
        "for i in range(len(value_series)):\n",
        "    index = labeling_df['Finding Labels'].value_counts().index[i].split(',')\n",
        "    if len(index) < 2: # dictionary data를 만들기 위해서 일단 단일의 질병만 가지고 있는 사람들을 dicstionary형태로 만듬.\n",
        "        value_dict[index[0]] =  labeling_df['Finding Labels'].value_counts()[i]\n",
        "label_list=sorted(list(value_dict.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TobEcdat1KxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7fc929b-2bb2-488d-db4c-fa406f192e21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Atelectasis',\n",
              " 'Cardiomegaly',\n",
              " 'Consolidation',\n",
              " 'Edema',\n",
              " 'Effusion',\n",
              " 'Emphysema',\n",
              " 'Fibrosis',\n",
              " 'Hernia',\n",
              " 'Infiltration',\n",
              " 'Mass',\n",
              " 'Nodule',\n",
              " 'Pleural_Thickening',\n",
              " 'Pneumonia',\n",
              " 'Pneumothorax']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG2pQJ51sBKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340dafe3-ab1d-4ab9-b963-c51294a3c75d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Atelectasis': 0,\n",
              " 'Cardiomegaly': 1,\n",
              " 'Consolidation': 2,\n",
              " 'Edema': 3,\n",
              " 'Effusion': 4,\n",
              " 'Emphysema': 5,\n",
              " 'Fibrosis': 6,\n",
              " 'Hernia': 7,\n",
              " 'Infiltration': 8,\n",
              " 'Mass': 9,\n",
              " 'Nodule': 10,\n",
              " 'Pleural_Thickening': 11,\n",
              " 'Pneumonia': 12,\n",
              " 'Pneumothorax': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "class2idx = {cls:idx for idx, cls in enumerate(label_list)}\n",
        "class2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTHti2Q0_NHh"
      },
      "outputs": [],
      "source": [
        "class Train_Dataset(Dataset):\n",
        "    def __init__(self, data_path,transform = None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data_path)\n",
        "    def __getitem__(self,idx):\n",
        "        path = self.data_path[idx]\n",
        "        img = np.array(Image.open(path))\n",
        "        img = img/255\n",
        "        img = img[:,:,np.newaxis]    \n",
        "        label = class2idx[df[df['Image Index']== path.split('/')[-1]]['Finding Labels'].values[0]]\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=img)\n",
        "            image = transformed['image']\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8PmaOQ5pF-3"
      },
      "outputs": [],
      "source": [
        "class val_Dataset(Dataset):\n",
        "    def __init__(self, data_path,transform = None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data_path)\n",
        "    def __getitem__(self,idx):\n",
        "        path = self.data_path[idx]\n",
        "        img = np.array(Image.open(path))\n",
        "        img = img/255\n",
        "        img = img[:,:,np.newaxis]    \n",
        "        label = class2idx[df[df['Image Index']== path.split('/')[-1]]['Finding Labels'].values[0]]\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=img)\n",
        "            image = transformed['image']\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs042d2Lb2sN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a160661d-0fb1-4112-9f4a-bdb5d3438f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.1.post1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.10.0.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=58bc595577622a28631751d84997fe931fec3caa9bdd2fcd9c6e5d5e8d4a7d9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install --upgrade --force-reinstall --no-deps albumentations\n",
        "!pip install albumentations==0.4.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjsRkywlpzRh"
      },
      "outputs": [],
      "source": [
        "import albumentations as A                                                                           \n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YFKEioT6sGU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ps3vqpTfykw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2285a205-2e10-4d5b-a78a-c0ea1521bdab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nA.RandomCrop(224, 224),\\n     A.OneOf([\\n              A.HorizontalFlip(p=1),\\n              A.RandomRotate90(p=1),\\n              A.VerticalFlip(p=1)            \\n    ], p=1), \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "data_transforms = {\n",
        "    'train': A.Compose(\n",
        "    [\n",
        "     ToTensorV2()\n",
        "     ]\n",
        "    ),\n",
        "    'val': A.Compose(\n",
        "        [\n",
        "     ToTensorV2()\n",
        "                            ]\n",
        "                           )\n",
        "}\n",
        "'''\n",
        "A.RandomCrop(224, 224),\n",
        "     A.OneOf([\n",
        "              A.HorizontalFlip(p=1),\n",
        "              A.RandomRotate90(p=1),\n",
        "              A.VerticalFlip(p=1)            \n",
        "    ], p=1), \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJc4KaBWjQQi"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(labeling_df,test_size = 0.2,random_state = 42,stratify = labeling_df['Finding Labels'])\n",
        "train_path = list(train_df['Image Index'].values)\n",
        "val_path = list(val_df['Image Index'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PMkgsM5iB_D"
      },
      "outputs": [],
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 14\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 2\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 20\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g3IdrnAk_dk"
      },
      "outputs": [],
      "source": [
        "train_data = Train_Dataset(train_path,transform = data_transforms['train'])\n",
        "val_data = val_Dataset(val_path,transform =  data_transforms['val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe0o3j_QgBQ3"
      },
      "outputs": [],
      "source": [
        "image_datasets = {'train' : train_data , 'val' : val_data}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) for x in ['train', 'val']}\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6M3XBpyrjto"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfqjEbZ-CIKf"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h251GCBQ4ZTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7608c5-39f2-4769-def5-42a3a65fd5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 12.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "#pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "timm.list_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XhrB-ZvDz29",
        "outputId": "157afb0e-9015-4ddd-f22e-280639d4cfc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adv_inception_v3',\n",
              " 'bat_resnext26ts',\n",
              " 'beit_base_patch16_224',\n",
              " 'beit_base_patch16_224_in22k',\n",
              " 'beit_base_patch16_384',\n",
              " 'beit_large_patch16_224',\n",
              " 'beit_large_patch16_224_in22k',\n",
              " 'beit_large_patch16_384',\n",
              " 'beit_large_patch16_512',\n",
              " 'botnet26t_256',\n",
              " 'botnet50ts_256',\n",
              " 'cait_m36_384',\n",
              " 'cait_m48_448',\n",
              " 'cait_s24_224',\n",
              " 'cait_s24_384',\n",
              " 'cait_s36_384',\n",
              " 'cait_xs24_384',\n",
              " 'cait_xxs24_224',\n",
              " 'cait_xxs24_384',\n",
              " 'cait_xxs36_224',\n",
              " 'cait_xxs36_384',\n",
              " 'coat_lite_mini',\n",
              " 'coat_lite_small',\n",
              " 'coat_lite_tiny',\n",
              " 'coat_mini',\n",
              " 'coat_tiny',\n",
              " 'convit_base',\n",
              " 'convit_small',\n",
              " 'convit_tiny',\n",
              " 'convmixer_768_32',\n",
              " 'convmixer_1024_20_ks9_p14',\n",
              " 'convmixer_1536_20',\n",
              " 'convnext_base',\n",
              " 'convnext_base_384_in22ft1k',\n",
              " 'convnext_base_in22ft1k',\n",
              " 'convnext_base_in22k',\n",
              " 'convnext_large',\n",
              " 'convnext_large_384_in22ft1k',\n",
              " 'convnext_large_in22ft1k',\n",
              " 'convnext_large_in22k',\n",
              " 'convnext_small',\n",
              " 'convnext_tiny',\n",
              " 'convnext_tiny_hnf',\n",
              " 'convnext_xlarge_384_in22ft1k',\n",
              " 'convnext_xlarge_in22ft1k',\n",
              " 'convnext_xlarge_in22k',\n",
              " 'crossvit_9_240',\n",
              " 'crossvit_9_dagger_240',\n",
              " 'crossvit_15_240',\n",
              " 'crossvit_15_dagger_240',\n",
              " 'crossvit_15_dagger_408',\n",
              " 'crossvit_18_240',\n",
              " 'crossvit_18_dagger_240',\n",
              " 'crossvit_18_dagger_408',\n",
              " 'crossvit_base_240',\n",
              " 'crossvit_small_240',\n",
              " 'crossvit_tiny_240',\n",
              " 'cspdarknet53',\n",
              " 'cspdarknet53_iabn',\n",
              " 'cspresnet50',\n",
              " 'cspresnet50d',\n",
              " 'cspresnet50w',\n",
              " 'cspresnext50',\n",
              " 'cspresnext50_iabn',\n",
              " 'darknet53',\n",
              " 'deit_base_distilled_patch16_224',\n",
              " 'deit_base_distilled_patch16_384',\n",
              " 'deit_base_patch16_224',\n",
              " 'deit_base_patch16_384',\n",
              " 'deit_small_distilled_patch16_224',\n",
              " 'deit_small_patch16_224',\n",
              " 'deit_tiny_distilled_patch16_224',\n",
              " 'deit_tiny_patch16_224',\n",
              " 'densenet121',\n",
              " 'densenet121d',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'densenet264',\n",
              " 'densenet264d_iabn',\n",
              " 'densenetblur121d',\n",
              " 'dla34',\n",
              " 'dla46_c',\n",
              " 'dla46x_c',\n",
              " 'dla60',\n",
              " 'dla60_res2net',\n",
              " 'dla60_res2next',\n",
              " 'dla60x',\n",
              " 'dla60x_c',\n",
              " 'dla102',\n",
              " 'dla102x',\n",
              " 'dla102x2',\n",
              " 'dla169',\n",
              " 'dm_nfnet_f0',\n",
              " 'dm_nfnet_f1',\n",
              " 'dm_nfnet_f2',\n",
              " 'dm_nfnet_f3',\n",
              " 'dm_nfnet_f4',\n",
              " 'dm_nfnet_f5',\n",
              " 'dm_nfnet_f6',\n",
              " 'dpn68',\n",
              " 'dpn68b',\n",
              " 'dpn92',\n",
              " 'dpn98',\n",
              " 'dpn107',\n",
              " 'dpn131',\n",
              " 'eca_botnext26ts_256',\n",
              " 'eca_halonext26ts',\n",
              " 'eca_nfnet_l0',\n",
              " 'eca_nfnet_l1',\n",
              " 'eca_nfnet_l2',\n",
              " 'eca_nfnet_l3',\n",
              " 'eca_resnet33ts',\n",
              " 'eca_resnext26ts',\n",
              " 'eca_vovnet39b',\n",
              " 'ecaresnet26t',\n",
              " 'ecaresnet50d',\n",
              " 'ecaresnet50d_pruned',\n",
              " 'ecaresnet50t',\n",
              " 'ecaresnet101d',\n",
              " 'ecaresnet101d_pruned',\n",
              " 'ecaresnet200d',\n",
              " 'ecaresnet269d',\n",
              " 'ecaresnetlight',\n",
              " 'ecaresnext26t_32x4d',\n",
              " 'ecaresnext50t_32x4d',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b1_pruned',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b2_pruned',\n",
              " 'efficientnet_b2a',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b3_pruned',\n",
              " 'efficientnet_b3a',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_b8',\n",
              " 'efficientnet_cc_b0_4e',\n",
              " 'efficientnet_cc_b0_8e',\n",
              " 'efficientnet_cc_b1_8e',\n",
              " 'efficientnet_el',\n",
              " 'efficientnet_el_pruned',\n",
              " 'efficientnet_em',\n",
              " 'efficientnet_es',\n",
              " 'efficientnet_es_pruned',\n",
              " 'efficientnet_l2',\n",
              " 'efficientnet_lite0',\n",
              " 'efficientnet_lite1',\n",
              " 'efficientnet_lite2',\n",
              " 'efficientnet_lite3',\n",
              " 'efficientnet_lite4',\n",
              " 'efficientnetv2_l',\n",
              " 'efficientnetv2_m',\n",
              " 'efficientnetv2_rw_m',\n",
              " 'efficientnetv2_rw_s',\n",
              " 'efficientnetv2_rw_t',\n",
              " 'efficientnetv2_s',\n",
              " 'efficientnetv2_xl',\n",
              " 'ens_adv_inception_resnet_v2',\n",
              " 'ese_vovnet19b_dw',\n",
              " 'ese_vovnet19b_slim',\n",
              " 'ese_vovnet19b_slim_dw',\n",
              " 'ese_vovnet39b',\n",
              " 'ese_vovnet39b_evos',\n",
              " 'ese_vovnet57b',\n",
              " 'ese_vovnet99b',\n",
              " 'ese_vovnet99b_iabn',\n",
              " 'fbnetc_100',\n",
              " 'fbnetv3_b',\n",
              " 'fbnetv3_d',\n",
              " 'fbnetv3_g',\n",
              " 'gc_efficientnetv2_rw_t',\n",
              " 'gcresnet33ts',\n",
              " 'gcresnet50t',\n",
              " 'gcresnext26ts',\n",
              " 'gcresnext50ts',\n",
              " 'gernet_l',\n",
              " 'gernet_m',\n",
              " 'gernet_s',\n",
              " 'ghostnet_050',\n",
              " 'ghostnet_100',\n",
              " 'ghostnet_130',\n",
              " 'gluon_inception_v3',\n",
              " 'gluon_resnet18_v1b',\n",
              " 'gluon_resnet34_v1b',\n",
              " 'gluon_resnet50_v1b',\n",
              " 'gluon_resnet50_v1c',\n",
              " 'gluon_resnet50_v1d',\n",
              " 'gluon_resnet50_v1s',\n",
              " 'gluon_resnet101_v1b',\n",
              " 'gluon_resnet101_v1c',\n",
              " 'gluon_resnet101_v1d',\n",
              " 'gluon_resnet101_v1s',\n",
              " 'gluon_resnet152_v1b',\n",
              " 'gluon_resnet152_v1c',\n",
              " 'gluon_resnet152_v1d',\n",
              " 'gluon_resnet152_v1s',\n",
              " 'gluon_resnext50_32x4d',\n",
              " 'gluon_resnext101_32x4d',\n",
              " 'gluon_resnext101_64x4d',\n",
              " 'gluon_senet154',\n",
              " 'gluon_seresnext50_32x4d',\n",
              " 'gluon_seresnext101_32x4d',\n",
              " 'gluon_seresnext101_64x4d',\n",
              " 'gluon_xception65',\n",
              " 'gmixer_12_224',\n",
              " 'gmixer_24_224',\n",
              " 'gmlp_b16_224',\n",
              " 'gmlp_s16_224',\n",
              " 'gmlp_ti16_224',\n",
              " 'halo2botnet50ts_256',\n",
              " 'halonet26t',\n",
              " 'halonet50ts',\n",
              " 'halonet_h1',\n",
              " 'haloregnetz_b',\n",
              " 'hardcorenas_a',\n",
              " 'hardcorenas_b',\n",
              " 'hardcorenas_c',\n",
              " 'hardcorenas_d',\n",
              " 'hardcorenas_e',\n",
              " 'hardcorenas_f',\n",
              " 'hrnet_w18',\n",
              " 'hrnet_w18_small',\n",
              " 'hrnet_w18_small_v2',\n",
              " 'hrnet_w30',\n",
              " 'hrnet_w32',\n",
              " 'hrnet_w40',\n",
              " 'hrnet_w44',\n",
              " 'hrnet_w48',\n",
              " 'hrnet_w64',\n",
              " 'ig_resnext101_32x8d',\n",
              " 'ig_resnext101_32x16d',\n",
              " 'ig_resnext101_32x32d',\n",
              " 'ig_resnext101_32x48d',\n",
              " 'inception_resnet_v2',\n",
              " 'inception_v3',\n",
              " 'inception_v4',\n",
              " 'jx_nest_base',\n",
              " 'jx_nest_small',\n",
              " 'jx_nest_tiny',\n",
              " 'lambda_resnet26rpt_256',\n",
              " 'lambda_resnet26t',\n",
              " 'lambda_resnet50ts',\n",
              " 'lamhalobotnet50ts_256',\n",
              " 'lcnet_035',\n",
              " 'lcnet_050',\n",
              " 'lcnet_075',\n",
              " 'lcnet_100',\n",
              " 'lcnet_150',\n",
              " 'legacy_senet154',\n",
              " 'legacy_seresnet18',\n",
              " 'legacy_seresnet34',\n",
              " 'legacy_seresnet50',\n",
              " 'legacy_seresnet101',\n",
              " 'legacy_seresnet152',\n",
              " 'legacy_seresnext26_32x4d',\n",
              " 'legacy_seresnext50_32x4d',\n",
              " 'legacy_seresnext101_32x4d',\n",
              " 'levit_128',\n",
              " 'levit_128s',\n",
              " 'levit_192',\n",
              " 'levit_256',\n",
              " 'levit_384',\n",
              " 'mixer_b16_224',\n",
              " 'mixer_b16_224_in21k',\n",
              " 'mixer_b16_224_miil',\n",
              " 'mixer_b16_224_miil_in21k',\n",
              " 'mixer_b32_224',\n",
              " 'mixer_l16_224',\n",
              " 'mixer_l16_224_in21k',\n",
              " 'mixer_l32_224',\n",
              " 'mixer_s16_224',\n",
              " 'mixer_s32_224',\n",
              " 'mixnet_l',\n",
              " 'mixnet_m',\n",
              " 'mixnet_s',\n",
              " 'mixnet_xl',\n",
              " 'mixnet_xxl',\n",
              " 'mnasnet_050',\n",
              " 'mnasnet_075',\n",
              " 'mnasnet_100',\n",
              " 'mnasnet_140',\n",
              " 'mnasnet_a1',\n",
              " 'mnasnet_b1',\n",
              " 'mnasnet_small',\n",
              " 'mobilenetv2_035',\n",
              " 'mobilenetv2_050',\n",
              " 'mobilenetv2_075',\n",
              " 'mobilenetv2_100',\n",
              " 'mobilenetv2_110d',\n",
              " 'mobilenetv2_120d',\n",
              " 'mobilenetv2_140',\n",
              " 'mobilenetv3_large_075',\n",
              " 'mobilenetv3_large_100',\n",
              " 'mobilenetv3_large_100_miil',\n",
              " 'mobilenetv3_large_100_miil_in21k',\n",
              " 'mobilenetv3_rw',\n",
              " 'mobilenetv3_small_050',\n",
              " 'mobilenetv3_small_075',\n",
              " 'mobilenetv3_small_100',\n",
              " 'nasnetalarge',\n",
              " 'nest_base',\n",
              " 'nest_small',\n",
              " 'nest_tiny',\n",
              " 'nf_ecaresnet26',\n",
              " 'nf_ecaresnet50',\n",
              " 'nf_ecaresnet101',\n",
              " 'nf_regnet_b0',\n",
              " 'nf_regnet_b1',\n",
              " 'nf_regnet_b2',\n",
              " 'nf_regnet_b3',\n",
              " 'nf_regnet_b4',\n",
              " 'nf_regnet_b5',\n",
              " 'nf_resnet26',\n",
              " 'nf_resnet50',\n",
              " 'nf_resnet101',\n",
              " 'nf_seresnet26',\n",
              " 'nf_seresnet50',\n",
              " 'nf_seresnet101',\n",
              " 'nfnet_f0',\n",
              " 'nfnet_f0s',\n",
              " 'nfnet_f1',\n",
              " 'nfnet_f1s',\n",
              " 'nfnet_f2',\n",
              " 'nfnet_f2s',\n",
              " 'nfnet_f3',\n",
              " 'nfnet_f3s',\n",
              " 'nfnet_f4',\n",
              " 'nfnet_f4s',\n",
              " 'nfnet_f5',\n",
              " 'nfnet_f5s',\n",
              " 'nfnet_f6',\n",
              " 'nfnet_f6s',\n",
              " 'nfnet_f7',\n",
              " 'nfnet_f7s',\n",
              " 'nfnet_l0',\n",
              " 'pit_b_224',\n",
              " 'pit_b_distilled_224',\n",
              " 'pit_s_224',\n",
              " 'pit_s_distilled_224',\n",
              " 'pit_ti_224',\n",
              " 'pit_ti_distilled_224',\n",
              " 'pit_xs_224',\n",
              " 'pit_xs_distilled_224',\n",
              " 'pnasnet5large',\n",
              " 'regnetx_002',\n",
              " 'regnetx_004',\n",
              " 'regnetx_006',\n",
              " 'regnetx_008',\n",
              " 'regnetx_016',\n",
              " 'regnetx_032',\n",
              " 'regnetx_040',\n",
              " 'regnetx_064',\n",
              " 'regnetx_080',\n",
              " 'regnetx_120',\n",
              " 'regnetx_160',\n",
              " 'regnetx_320',\n",
              " 'regnety_002',\n",
              " 'regnety_004',\n",
              " 'regnety_006',\n",
              " 'regnety_008',\n",
              " 'regnety_016',\n",
              " 'regnety_032',\n",
              " 'regnety_040',\n",
              " 'regnety_064',\n",
              " 'regnety_080',\n",
              " 'regnety_120',\n",
              " 'regnety_160',\n",
              " 'regnety_320',\n",
              " 'regnetz_b16',\n",
              " 'regnetz_c16',\n",
              " 'regnetz_d8',\n",
              " 'regnetz_d8_evob',\n",
              " 'regnetz_d8_evos',\n",
              " 'regnetz_d32',\n",
              " 'regnetz_e8',\n",
              " 'repvgg_a2',\n",
              " 'repvgg_b0',\n",
              " 'repvgg_b1',\n",
              " 'repvgg_b1g4',\n",
              " 'repvgg_b2',\n",
              " 'repvgg_b2g4',\n",
              " 'repvgg_b3',\n",
              " 'repvgg_b3g4',\n",
              " 'res2net50_14w_8s',\n",
              " 'res2net50_26w_4s',\n",
              " 'res2net50_26w_6s',\n",
              " 'res2net50_26w_8s',\n",
              " 'res2net50_48w_2s',\n",
              " 'res2net101_26w_4s',\n",
              " 'res2next50',\n",
              " 'resmlp_12_224',\n",
              " 'resmlp_12_224_dino',\n",
              " 'resmlp_12_distilled_224',\n",
              " 'resmlp_24_224',\n",
              " 'resmlp_24_224_dino',\n",
              " 'resmlp_24_distilled_224',\n",
              " 'resmlp_36_224',\n",
              " 'resmlp_36_distilled_224',\n",
              " 'resmlp_big_24_224',\n",
              " 'resmlp_big_24_224_in22ft1k',\n",
              " 'resmlp_big_24_distilled_224',\n",
              " 'resnest14d',\n",
              " 'resnest26d',\n",
              " 'resnest50d',\n",
              " 'resnest50d_1s4x24d',\n",
              " 'resnest50d_4s2x40d',\n",
              " 'resnest101e',\n",
              " 'resnest200e',\n",
              " 'resnest269e',\n",
              " 'resnet18',\n",
              " 'resnet18d',\n",
              " 'resnet26',\n",
              " 'resnet26d',\n",
              " 'resnet26t',\n",
              " 'resnet32ts',\n",
              " 'resnet33ts',\n",
              " 'resnet34',\n",
              " 'resnet34d',\n",
              " 'resnet50',\n",
              " 'resnet50_gn',\n",
              " 'resnet50d',\n",
              " 'resnet50t',\n",
              " 'resnet51q',\n",
              " 'resnet61q',\n",
              " 'resnet101',\n",
              " 'resnet101d',\n",
              " 'resnet152',\n",
              " 'resnet152d',\n",
              " 'resnet200',\n",
              " 'resnet200d',\n",
              " 'resnetblur18',\n",
              " 'resnetblur50',\n",
              " 'resnetrs50',\n",
              " 'resnetrs101',\n",
              " 'resnetrs152',\n",
              " 'resnetrs200',\n",
              " 'resnetrs270',\n",
              " 'resnetrs350',\n",
              " 'resnetrs420',\n",
              " 'resnetv2_50',\n",
              " 'resnetv2_50d',\n",
              " 'resnetv2_50d_evob',\n",
              " 'resnetv2_50d_evos',\n",
              " 'resnetv2_50d_gn',\n",
              " 'resnetv2_50t',\n",
              " 'resnetv2_50x1_bit_distilled',\n",
              " 'resnetv2_50x1_bitm',\n",
              " 'resnetv2_50x1_bitm_in21k',\n",
              " 'resnetv2_50x3_bitm',\n",
              " 'resnetv2_50x3_bitm_in21k',\n",
              " 'resnetv2_101',\n",
              " 'resnetv2_101d',\n",
              " 'resnetv2_101x1_bitm',\n",
              " 'resnetv2_101x1_bitm_in21k',\n",
              " 'resnetv2_101x3_bitm',\n",
              " 'resnetv2_101x3_bitm_in21k',\n",
              " 'resnetv2_152',\n",
              " 'resnetv2_152d',\n",
              " 'resnetv2_152x2_bit_teacher',\n",
              " 'resnetv2_152x2_bit_teacher_384',\n",
              " 'resnetv2_152x2_bitm',\n",
              " 'resnetv2_152x2_bitm_in21k',\n",
              " 'resnetv2_152x4_bitm',\n",
              " 'resnetv2_152x4_bitm_in21k',\n",
              " 'resnext26ts',\n",
              " 'resnext50_32x4d',\n",
              " 'resnext50d_32x4d',\n",
              " 'resnext101_32x4d',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'rexnet_100',\n",
              " 'rexnet_130',\n",
              " 'rexnet_150',\n",
              " 'rexnet_200',\n",
              " 'rexnetr_100',\n",
              " 'rexnetr_130',\n",
              " 'rexnetr_150',\n",
              " 'rexnetr_200',\n",
              " 'sebotnet33ts_256',\n",
              " 'sehalonet33ts',\n",
              " 'selecsls42',\n",
              " 'selecsls42b',\n",
              " 'selecsls60',\n",
              " 'selecsls60b',\n",
              " 'selecsls84',\n",
              " 'semnasnet_050',\n",
              " 'semnasnet_075',\n",
              " 'semnasnet_100',\n",
              " 'semnasnet_140',\n",
              " 'senet154',\n",
              " 'seresnet18',\n",
              " 'seresnet33ts',\n",
              " 'seresnet34',\n",
              " 'seresnet50',\n",
              " 'seresnet50t',\n",
              " 'seresnet101',\n",
              " 'seresnet152',\n",
              " 'seresnet152d',\n",
              " 'seresnet200d',\n",
              " 'seresnet269d',\n",
              " 'seresnext26d_32x4d',\n",
              " 'seresnext26t_32x4d',\n",
              " 'seresnext26tn_32x4d',\n",
              " 'seresnext26ts',\n",
              " 'seresnext50_32x4d',\n",
              " 'seresnext101_32x4d',\n",
              " 'seresnext101_32x8d',\n",
              " 'skresnet18',\n",
              " 'skresnet34',\n",
              " 'skresnet50',\n",
              " 'skresnet50d',\n",
              " 'skresnext50_32x4d',\n",
              " 'spnasnet_100',\n",
              " 'ssl_resnet18',\n",
              " 'ssl_resnet50',\n",
              " 'ssl_resnext50_32x4d',\n",
              " 'ssl_resnext101_32x4d',\n",
              " 'ssl_resnext101_32x8d',\n",
              " 'ssl_resnext101_32x16d',\n",
              " 'swin_base_patch4_window7_224',\n",
              " 'swin_base_patch4_window7_224_in22k',\n",
              " 'swin_base_patch4_window12_384',\n",
              " 'swin_base_patch4_window12_384_in22k',\n",
              " 'swin_large_patch4_window7_224',\n",
              " 'swin_large_patch4_window7_224_in22k',\n",
              " 'swin_large_patch4_window12_384',\n",
              " 'swin_large_patch4_window12_384_in22k',\n",
              " 'swin_small_patch4_window7_224',\n",
              " 'swin_tiny_patch4_window7_224',\n",
              " 'swsl_resnet18',\n",
              " 'swsl_resnet50',\n",
              " 'swsl_resnext50_32x4d',\n",
              " 'swsl_resnext101_32x4d',\n",
              " 'swsl_resnext101_32x8d',\n",
              " 'swsl_resnext101_32x16d',\n",
              " 'tf_efficientnet_b0',\n",
              " 'tf_efficientnet_b0_ap',\n",
              " 'tf_efficientnet_b0_ns',\n",
              " 'tf_efficientnet_b1',\n",
              " 'tf_efficientnet_b1_ap',\n",
              " 'tf_efficientnet_b1_ns',\n",
              " 'tf_efficientnet_b2',\n",
              " 'tf_efficientnet_b2_ap',\n",
              " 'tf_efficientnet_b2_ns',\n",
              " 'tf_efficientnet_b3',\n",
              " 'tf_efficientnet_b3_ap',\n",
              " 'tf_efficientnet_b3_ns',\n",
              " 'tf_efficientnet_b4',\n",
              " 'tf_efficientnet_b4_ap',\n",
              " 'tf_efficientnet_b4_ns',\n",
              " 'tf_efficientnet_b5',\n",
              " 'tf_efficientnet_b5_ap',\n",
              " 'tf_efficientnet_b5_ns',\n",
              " 'tf_efficientnet_b6',\n",
              " 'tf_efficientnet_b6_ap',\n",
              " 'tf_efficientnet_b6_ns',\n",
              " 'tf_efficientnet_b7',\n",
              " 'tf_efficientnet_b7_ap',\n",
              " 'tf_efficientnet_b7_ns',\n",
              " 'tf_efficientnet_b8',\n",
              " 'tf_efficientnet_b8_ap',\n",
              " 'tf_efficientnet_cc_b0_4e',\n",
              " 'tf_efficientnet_cc_b0_8e',\n",
              " 'tf_efficientnet_cc_b1_8e',\n",
              " 'tf_efficientnet_el',\n",
              " 'tf_efficientnet_em',\n",
              " 'tf_efficientnet_es',\n",
              " 'tf_efficientnet_l2_ns',\n",
              " 'tf_efficientnet_l2_ns_475',\n",
              " 'tf_efficientnet_lite0',\n",
              " 'tf_efficientnet_lite1',\n",
              " 'tf_efficientnet_lite2',\n",
              " 'tf_efficientnet_lite3',\n",
              " 'tf_efficientnet_lite4',\n",
              " 'tf_efficientnetv2_b0',\n",
              " 'tf_efficientnetv2_b1',\n",
              " 'tf_efficientnetv2_b2',\n",
              " 'tf_efficientnetv2_b3',\n",
              " 'tf_efficientnetv2_l',\n",
              " 'tf_efficientnetv2_l_in21ft1k',\n",
              " 'tf_efficientnetv2_l_in21k',\n",
              " 'tf_efficientnetv2_m',\n",
              " 'tf_efficientnetv2_m_in21ft1k',\n",
              " 'tf_efficientnetv2_m_in21k',\n",
              " 'tf_efficientnetv2_s',\n",
              " 'tf_efficientnetv2_s_in21ft1k',\n",
              " 'tf_efficientnetv2_s_in21k',\n",
              " 'tf_efficientnetv2_xl_in21ft1k',\n",
              " 'tf_efficientnetv2_xl_in21k',\n",
              " 'tf_inception_v3',\n",
              " 'tf_mixnet_l',\n",
              " 'tf_mixnet_m',\n",
              " 'tf_mixnet_s',\n",
              " 'tf_mobilenetv3_large_075',\n",
              " 'tf_mobilenetv3_large_100',\n",
              " 'tf_mobilenetv3_large_minimal_100',\n",
              " 'tf_mobilenetv3_small_075',\n",
              " 'tf_mobilenetv3_small_100',\n",
              " 'tf_mobilenetv3_small_minimal_100',\n",
              " 'tinynet_a',\n",
              " 'tinynet_b',\n",
              " 'tinynet_c',\n",
              " 'tinynet_d',\n",
              " 'tinynet_e',\n",
              " 'tnt_b_patch16_224',\n",
              " 'tnt_s_patch16_224',\n",
              " 'tresnet_l',\n",
              " 'tresnet_l_448',\n",
              " 'tresnet_m',\n",
              " 'tresnet_m_448',\n",
              " 'tresnet_m_miil_in21k',\n",
              " 'tresnet_xl',\n",
              " 'tresnet_xl_448',\n",
              " 'tv_densenet121',\n",
              " 'tv_resnet34',\n",
              " 'tv_resnet50',\n",
              " 'tv_resnet101',\n",
              " 'tv_resnet152',\n",
              " 'tv_resnext50_32x4d',\n",
              " 'twins_pcpvt_base',\n",
              " 'twins_pcpvt_large',\n",
              " 'twins_pcpvt_small',\n",
              " 'twins_svt_base',\n",
              " 'twins_svt_large',\n",
              " 'twins_svt_small',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'visformer_small',\n",
              " 'visformer_tiny',\n",
              " 'vit_base_patch8_224',\n",
              " 'vit_base_patch8_224_in21k',\n",
              " 'vit_base_patch16_224',\n",
              " 'vit_base_patch16_224_in21k',\n",
              " 'vit_base_patch16_224_miil',\n",
              " 'vit_base_patch16_224_miil_in21k',\n",
              " 'vit_base_patch16_384',\n",
              " 'vit_base_patch16_sam_224',\n",
              " 'vit_base_patch32_224',\n",
              " 'vit_base_patch32_224_in21k',\n",
              " 'vit_base_patch32_384',\n",
              " 'vit_base_patch32_sam_224',\n",
              " 'vit_base_r26_s32_224',\n",
              " 'vit_base_r50_s16_224',\n",
              " 'vit_base_r50_s16_224_in21k',\n",
              " 'vit_base_r50_s16_384',\n",
              " 'vit_base_resnet26d_224',\n",
              " 'vit_base_resnet50_224_in21k',\n",
              " 'vit_base_resnet50_384',\n",
              " 'vit_base_resnet50d_224',\n",
              " 'vit_giant_patch14_224',\n",
              " 'vit_gigantic_patch14_224',\n",
              " 'vit_huge_patch14_224',\n",
              " 'vit_huge_patch14_224_in21k',\n",
              " 'vit_large_patch16_224',\n",
              " 'vit_large_patch16_224_in21k',\n",
              " 'vit_large_patch16_384',\n",
              " 'vit_large_patch32_224',\n",
              " 'vit_large_patch32_224_in21k',\n",
              " 'vit_large_patch32_384',\n",
              " 'vit_large_r50_s32_224',\n",
              " 'vit_large_r50_s32_224_in21k',\n",
              " 'vit_large_r50_s32_384',\n",
              " 'vit_small_patch16_224',\n",
              " 'vit_small_patch16_224_in21k',\n",
              " 'vit_small_patch16_384',\n",
              " 'vit_small_patch32_224',\n",
              " 'vit_small_patch32_224_in21k',\n",
              " 'vit_small_patch32_384',\n",
              " 'vit_small_r26_s32_224',\n",
              " 'vit_small_r26_s32_224_in21k',\n",
              " 'vit_small_r26_s32_384',\n",
              " 'vit_small_resnet26d_224',\n",
              " 'vit_small_resnet50d_s16_224',\n",
              " 'vit_tiny_patch16_224',\n",
              " 'vit_tiny_patch16_224_in21k',\n",
              " 'vit_tiny_patch16_384',\n",
              " 'vit_tiny_r_s16_p8_224',\n",
              " 'vit_tiny_r_s16_p8_224_in21k',\n",
              " 'vit_tiny_r_s16_p8_384',\n",
              " 'vovnet39a',\n",
              " 'vovnet57a',\n",
              " 'wide_resnet50_2',\n",
              " 'wide_resnet101_2',\n",
              " 'xception',\n",
              " 'xception41',\n",
              " 'xception65',\n",
              " 'xception71',\n",
              " 'xcit_large_24_p8_224',\n",
              " 'xcit_large_24_p8_224_dist',\n",
              " 'xcit_large_24_p8_384_dist',\n",
              " 'xcit_large_24_p16_224',\n",
              " 'xcit_large_24_p16_224_dist',\n",
              " 'xcit_large_24_p16_384_dist',\n",
              " 'xcit_medium_24_p8_224',\n",
              " 'xcit_medium_24_p8_224_dist',\n",
              " 'xcit_medium_24_p8_384_dist',\n",
              " 'xcit_medium_24_p16_224',\n",
              " 'xcit_medium_24_p16_224_dist',\n",
              " 'xcit_medium_24_p16_384_dist',\n",
              " 'xcit_nano_12_p8_224',\n",
              " 'xcit_nano_12_p8_224_dist',\n",
              " 'xcit_nano_12_p8_384_dist',\n",
              " 'xcit_nano_12_p16_224',\n",
              " 'xcit_nano_12_p16_224_dist',\n",
              " 'xcit_nano_12_p16_384_dist',\n",
              " 'xcit_small_12_p8_224',\n",
              " 'xcit_small_12_p8_224_dist',\n",
              " 'xcit_small_12_p8_384_dist',\n",
              " 'xcit_small_12_p16_224',\n",
              " 'xcit_small_12_p16_224_dist',\n",
              " 'xcit_small_12_p16_384_dist',\n",
              " 'xcit_small_24_p8_224',\n",
              " 'xcit_small_24_p8_224_dist',\n",
              " 'xcit_small_24_p8_384_dist',\n",
              " 'xcit_small_24_p16_224',\n",
              " 'xcit_small_24_p16_224_dist',\n",
              " 'xcit_small_24_p16_384_dist',\n",
              " 'xcit_tiny_12_p8_224',\n",
              " 'xcit_tiny_12_p8_224_dist',\n",
              " 'xcit_tiny_12_p8_384_dist',\n",
              " 'xcit_tiny_12_p16_224',\n",
              " 'xcit_tiny_12_p16_224_dist',\n",
              " 'xcit_tiny_12_p16_384_dist',\n",
              " 'xcit_tiny_24_p8_224',\n",
              " 'xcit_tiny_24_p8_224_dist',\n",
              " 'xcit_tiny_24_p8_384_dist',\n",
              " 'xcit_tiny_24_p16_224',\n",
              " 'xcit_tiny_24_p16_224_dist',\n",
              " 'xcit_tiny_24_p16_384_dist']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HloE48OKoBDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "759ec7f4-5bf6-42bb-eb3c-dff08f22a654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet152_a1h-dc400468.pth\" to /root/.cache/torch/hub/checkpoints/resnet152_a1h-dc400468.pth\n"
          ]
        }
      ],
      "source": [
        "model = timm.create_model('resnet152', pretrained=True, num_classes = 14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_nCnG5juDrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a13a5c-c386-4e36-d39e-a29e6671035a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "model.conv1.padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLahGXDRpbtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2f70e4-64ab-4c03-b22e-4542aee4ed4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (23): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (24): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (25): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (26): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (27): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (28): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (29): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (30): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (31): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (32): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (33): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (34): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (35): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (fc): Linear(in_features=2048, out_features=14, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "num_classes = 14\n",
        "num_ftrs = model.fc.in_features\n",
        "model.conv1 = nn.Conv2d(1,64, kernel_size=(7,7), stride = (2,2), padding= (3,3), bias = False)\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "device = torch.device('cuda:0')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwjGkEx_usxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524a25cf-8d99-4b63-a840-1803baa3b458"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (23): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (24): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (25): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (26): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (27): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (28): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (29): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (30): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (31): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (32): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (33): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (34): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (35): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (fc): Linear(in_features=2048, out_features=14, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "model.parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3kbOWSRq5or",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7f69efab-3055-4e75-a3da-e76a12c684cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor name, param in model.named_parameters(): \\n  print(f'name:{name}') \\n  print(type(param))\\n  print(f'param.shape:{param.shape}')\\n  print(f'param.requries_grad:{param.requires_grad}') \\n  print('=====')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "'''\n",
        "for name, param in model.named_parameters(): \n",
        "  print(f'name:{name}') \n",
        "  print(type(param))\n",
        "  print(f'param.shape:{param.shape}')\n",
        "  print(f'param.requries_grad:{param.requires_grad}') \n",
        "  print('=====')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f9EP22QrzC7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "47cce8b6-45b7-46f8-be61-8694463c7067"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor name, param in model.named_parameters(): \\n  if name in ['conv1.weight']: \\n    param.requires_grad = True \\n  else: \\n    param.requires_grad = False\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "'''\n",
        "for name, param in model.named_parameters(): \n",
        "  if name in ['conv1.weight']: \n",
        "    param.requires_grad = True \n",
        "  else: \n",
        "    param.requires_grad = False\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_IKX3NkrjyH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "e188ecd4-c4a6-4a68-b959-be8eb7b4f1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 7, 7])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f29827e9110>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#레이어 시각화\n",
        "\n",
        "for w in model.parameters():\n",
        "    w = w.data.cpu()\n",
        "    print(w.shape)\n",
        "    break\n",
        "\n",
        "# normalize weights\n",
        "min_w = torch.min(w)\n",
        "w1 = (-1/(2 * min_w)) * w + 0.5\n",
        "\n",
        "# make grid to display it\n",
        "grid_size = len(w1)\n",
        "x_grid = [w1[i] for i in range(grid_size)]\n",
        "x_grid = torchvision.utils.make_grid(x_grid, nrow=8, padding=1)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(x_grid.permute(2,1,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3FkWZ-D8ztG"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score , roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gouR33TpCExU"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "    train_acc_history = []\n",
        "    train_loss_hist = [] \n",
        "    train_precision = [] \n",
        "    train_recall = [] \n",
        "    train_auc = [] \n",
        "    train_f1_score =[]\n",
        "    val_loss_hist = []\n",
        "    val_acc_history = [] \n",
        "    val_precision = [] \n",
        "    val_recall = [] \n",
        "    val_auc = [] \n",
        "    val_f1_score = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            start = time.time()\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            running_precision =0\n",
        "            running_recall = 0\n",
        "            running_f1_score =0 \n",
        "            running_auc = 0\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device = device, dtype = torch.float32)\n",
        "                labels = labels.to(device = device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    outputs = model(inputs) \n",
        "                    pred = torch.argmax(nn.Softmax(dim = 1)(outputs),axis = 1)\n",
        "                    loss = criterion(outputs,labels)\n",
        "                    if phase == 'train':\n",
        "                    # backward + optimize only if in training phase\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(pred == labels.data)\n",
        "                running_f1_score += f1_score(labels.detach().cpu().numpy(), pred.detach().cpu().numpy() , average = 'macro')\n",
        "                '''\n",
        "                running_precision += precision_score(labels , outputs)\n",
        "                running_recall += recall_score(labels , outputs)\n",
        "                running_auc += roc_auc_score(labels , outputs)\n",
        "                running_f1_score += f1_score(labels.detach().cpu().numpy(), pred , average = 'macro')\n",
        "                '''\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            epoch_f1_score = running_f1_score/len(dataloaders[phase].dataset)\n",
        "            '''\n",
        "            epoch_precision = running_precision/ len(dataloaders[phase].dataset)\n",
        "            epoch_recall = running_recall/len(dataloaders[phase].dataset)\n",
        "\n",
        "            epoch_auc = running_auc/len(dataloaders[phase].dataset)\n",
        "            '''\n",
        "            if phase == 'train':\n",
        "              train_acc_history.append(epoch_acc)\n",
        "              train_loss_hist.append(epoch_loss)\n",
        "              train_f1_score.append(epoch_f1_score)\n",
        "\n",
        "              '''\n",
        "              train_precision.append(epoch_precision)\n",
        "              train_recall.append(epoch_recall)\n",
        "              train_auc.append(epoch_auc)\n",
        "              train_f1_score.append(epoch_f1_score)\n",
        "\n",
        "              '''\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f},f1 :{:.4f},Time : {:.4f}'.format(phase, epoch_loss ,epoch_acc,epoch_f1_score,time.time()-start))\n",
        "            #, P : {.4f} , R :{.4f} , AUC : {.4f},f1 :{:.4f}  , , epoch_precision,epoch_recall, epoch_auc, epoch_f1_score  \n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                val_loss_hist.append(epoch_loss)\n",
        "                val_f1_score.append(epoch_f1_score)\n",
        "                '''\n",
        "                val_precision.append(epoch_precision)\n",
        "                val_recall.append(epoch_recall)\n",
        "                val_auc.append(epoch_auc)\n",
        "                val_f1_score.append(epoch_f1_score)\n",
        "\n",
        "                '''\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    train_dict = {'Loss' : train_loss_hist , 'Accuracy' : train_acc_history, 'f1' : train_f1_score }\n",
        "    #, 'Precision' : train_precision, 'Recall' : train_recall, 'Auc' : train_auc\n",
        "    val_dict = {'Loss' :val_loss_hist , 'Accuracy' : val_acc_history, 'f1' : val_f1_score}\n",
        "    #, 'Precision' : val_precision , 'Recall' : val_recall, 'Auc' : val_auc , \n",
        "    return model, train_dict ,val_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpK1P0JhsLZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f0e4fa4-19b2-4eae-dcd5-4e40f57dabbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]           3,136\n",
            "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
            "              ReLU-3         [-1, 64, 256, 256]               0\n",
            "         MaxPool2d-4         [-1, 64, 128, 128]               0\n",
            "            Conv2d-5         [-1, 64, 128, 128]           4,096\n",
            "       BatchNorm2d-6         [-1, 64, 128, 128]             128\n",
            "              ReLU-7         [-1, 64, 128, 128]               0\n",
            "            Conv2d-8         [-1, 64, 128, 128]          36,864\n",
            "       BatchNorm2d-9         [-1, 64, 128, 128]             128\n",
            "             ReLU-10         [-1, 64, 128, 128]               0\n",
            "           Conv2d-11        [-1, 256, 128, 128]          16,384\n",
            "      BatchNorm2d-12        [-1, 256, 128, 128]             512\n",
            "           Conv2d-13        [-1, 256, 128, 128]          16,384\n",
            "      BatchNorm2d-14        [-1, 256, 128, 128]             512\n",
            "             ReLU-15        [-1, 256, 128, 128]               0\n",
            "       Bottleneck-16        [-1, 256, 128, 128]               0\n",
            "           Conv2d-17         [-1, 64, 128, 128]          16,384\n",
            "      BatchNorm2d-18         [-1, 64, 128, 128]             128\n",
            "             ReLU-19         [-1, 64, 128, 128]               0\n",
            "           Conv2d-20         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-21         [-1, 64, 128, 128]             128\n",
            "             ReLU-22         [-1, 64, 128, 128]               0\n",
            "           Conv2d-23        [-1, 256, 128, 128]          16,384\n",
            "      BatchNorm2d-24        [-1, 256, 128, 128]             512\n",
            "             ReLU-25        [-1, 256, 128, 128]               0\n",
            "       Bottleneck-26        [-1, 256, 128, 128]               0\n",
            "           Conv2d-27         [-1, 64, 128, 128]          16,384\n",
            "      BatchNorm2d-28         [-1, 64, 128, 128]             128\n",
            "             ReLU-29         [-1, 64, 128, 128]               0\n",
            "           Conv2d-30         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-31         [-1, 64, 128, 128]             128\n",
            "             ReLU-32         [-1, 64, 128, 128]               0\n",
            "           Conv2d-33        [-1, 256, 128, 128]          16,384\n",
            "      BatchNorm2d-34        [-1, 256, 128, 128]             512\n",
            "             ReLU-35        [-1, 256, 128, 128]               0\n",
            "       Bottleneck-36        [-1, 256, 128, 128]               0\n",
            "           Conv2d-37        [-1, 128, 128, 128]          32,768\n",
            "      BatchNorm2d-38        [-1, 128, 128, 128]             256\n",
            "             ReLU-39        [-1, 128, 128, 128]               0\n",
            "           Conv2d-40          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 64, 64]             256\n",
            "             ReLU-42          [-1, 128, 64, 64]               0\n",
            "           Conv2d-43          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 64, 64]           1,024\n",
            "           Conv2d-45          [-1, 512, 64, 64]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-47          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-48          [-1, 512, 64, 64]               0\n",
            "           Conv2d-49          [-1, 128, 64, 64]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 64, 64]             256\n",
            "             ReLU-51          [-1, 128, 64, 64]               0\n",
            "           Conv2d-52          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 64, 64]             256\n",
            "             ReLU-54          [-1, 128, 64, 64]               0\n",
            "           Conv2d-55          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-57          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-58          [-1, 512, 64, 64]               0\n",
            "           Conv2d-59          [-1, 128, 64, 64]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 64, 64]             256\n",
            "             ReLU-61          [-1, 128, 64, 64]               0\n",
            "           Conv2d-62          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 64, 64]             256\n",
            "             ReLU-64          [-1, 128, 64, 64]               0\n",
            "           Conv2d-65          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-67          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-68          [-1, 512, 64, 64]               0\n",
            "           Conv2d-69          [-1, 128, 64, 64]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 64, 64]             256\n",
            "             ReLU-71          [-1, 128, 64, 64]               0\n",
            "           Conv2d-72          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 64, 64]             256\n",
            "             ReLU-74          [-1, 128, 64, 64]               0\n",
            "           Conv2d-75          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-77          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-78          [-1, 512, 64, 64]               0\n",
            "           Conv2d-79          [-1, 128, 64, 64]          65,536\n",
            "      BatchNorm2d-80          [-1, 128, 64, 64]             256\n",
            "             ReLU-81          [-1, 128, 64, 64]               0\n",
            "           Conv2d-82          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-83          [-1, 128, 64, 64]             256\n",
            "             ReLU-84          [-1, 128, 64, 64]               0\n",
            "           Conv2d-85          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-86          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-87          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-88          [-1, 512, 64, 64]               0\n",
            "           Conv2d-89          [-1, 128, 64, 64]          65,536\n",
            "      BatchNorm2d-90          [-1, 128, 64, 64]             256\n",
            "             ReLU-91          [-1, 128, 64, 64]               0\n",
            "           Conv2d-92          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-93          [-1, 128, 64, 64]             256\n",
            "             ReLU-94          [-1, 128, 64, 64]               0\n",
            "           Conv2d-95          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-96          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-97          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-98          [-1, 512, 64, 64]               0\n",
            "           Conv2d-99          [-1, 128, 64, 64]          65,536\n",
            "     BatchNorm2d-100          [-1, 128, 64, 64]             256\n",
            "            ReLU-101          [-1, 128, 64, 64]               0\n",
            "          Conv2d-102          [-1, 128, 64, 64]         147,456\n",
            "     BatchNorm2d-103          [-1, 128, 64, 64]             256\n",
            "            ReLU-104          [-1, 128, 64, 64]               0\n",
            "          Conv2d-105          [-1, 512, 64, 64]          65,536\n",
            "     BatchNorm2d-106          [-1, 512, 64, 64]           1,024\n",
            "            ReLU-107          [-1, 512, 64, 64]               0\n",
            "      Bottleneck-108          [-1, 512, 64, 64]               0\n",
            "          Conv2d-109          [-1, 128, 64, 64]          65,536\n",
            "     BatchNorm2d-110          [-1, 128, 64, 64]             256\n",
            "            ReLU-111          [-1, 128, 64, 64]               0\n",
            "          Conv2d-112          [-1, 128, 64, 64]         147,456\n",
            "     BatchNorm2d-113          [-1, 128, 64, 64]             256\n",
            "            ReLU-114          [-1, 128, 64, 64]               0\n",
            "          Conv2d-115          [-1, 512, 64, 64]          65,536\n",
            "     BatchNorm2d-116          [-1, 512, 64, 64]           1,024\n",
            "            ReLU-117          [-1, 512, 64, 64]               0\n",
            "      Bottleneck-118          [-1, 512, 64, 64]               0\n",
            "          Conv2d-119          [-1, 256, 64, 64]         131,072\n",
            "     BatchNorm2d-120          [-1, 256, 64, 64]             512\n",
            "            ReLU-121          [-1, 256, 64, 64]               0\n",
            "          Conv2d-122          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-123          [-1, 256, 32, 32]             512\n",
            "            ReLU-124          [-1, 256, 32, 32]               0\n",
            "          Conv2d-125         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-126         [-1, 1024, 32, 32]           2,048\n",
            "          Conv2d-127         [-1, 1024, 32, 32]         524,288\n",
            "     BatchNorm2d-128         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-129         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-130         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-131          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 32, 32]             512\n",
            "            ReLU-133          [-1, 256, 32, 32]               0\n",
            "          Conv2d-134          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 32, 32]             512\n",
            "            ReLU-136          [-1, 256, 32, 32]               0\n",
            "          Conv2d-137         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-139         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-140         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-141          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-142          [-1, 256, 32, 32]             512\n",
            "            ReLU-143          [-1, 256, 32, 32]               0\n",
            "          Conv2d-144          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-145          [-1, 256, 32, 32]             512\n",
            "            ReLU-146          [-1, 256, 32, 32]               0\n",
            "          Conv2d-147         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-148         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-149         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-150         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-151          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-152          [-1, 256, 32, 32]             512\n",
            "            ReLU-153          [-1, 256, 32, 32]               0\n",
            "          Conv2d-154          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-155          [-1, 256, 32, 32]             512\n",
            "            ReLU-156          [-1, 256, 32, 32]               0\n",
            "          Conv2d-157         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-158         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-159         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-160         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-161          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-162          [-1, 256, 32, 32]             512\n",
            "            ReLU-163          [-1, 256, 32, 32]               0\n",
            "          Conv2d-164          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-165          [-1, 256, 32, 32]             512\n",
            "            ReLU-166          [-1, 256, 32, 32]               0\n",
            "          Conv2d-167         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-168         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-169         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-170         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-171          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-172          [-1, 256, 32, 32]             512\n",
            "            ReLU-173          [-1, 256, 32, 32]               0\n",
            "          Conv2d-174          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-175          [-1, 256, 32, 32]             512\n",
            "            ReLU-176          [-1, 256, 32, 32]               0\n",
            "          Conv2d-177         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-178         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-179         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-180         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-181          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-182          [-1, 256, 32, 32]             512\n",
            "            ReLU-183          [-1, 256, 32, 32]               0\n",
            "          Conv2d-184          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-185          [-1, 256, 32, 32]             512\n",
            "            ReLU-186          [-1, 256, 32, 32]               0\n",
            "          Conv2d-187         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-188         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-189         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-190         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-191          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-192          [-1, 256, 32, 32]             512\n",
            "            ReLU-193          [-1, 256, 32, 32]               0\n",
            "          Conv2d-194          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-195          [-1, 256, 32, 32]             512\n",
            "            ReLU-196          [-1, 256, 32, 32]               0\n",
            "          Conv2d-197         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-198         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-199         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-200         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-201          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-202          [-1, 256, 32, 32]             512\n",
            "            ReLU-203          [-1, 256, 32, 32]               0\n",
            "          Conv2d-204          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-205          [-1, 256, 32, 32]             512\n",
            "            ReLU-206          [-1, 256, 32, 32]               0\n",
            "          Conv2d-207         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-208         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-209         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-210         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-211          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-212          [-1, 256, 32, 32]             512\n",
            "            ReLU-213          [-1, 256, 32, 32]               0\n",
            "          Conv2d-214          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-215          [-1, 256, 32, 32]             512\n",
            "            ReLU-216          [-1, 256, 32, 32]               0\n",
            "          Conv2d-217         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-218         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-219         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-220         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-221          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-222          [-1, 256, 32, 32]             512\n",
            "            ReLU-223          [-1, 256, 32, 32]               0\n",
            "          Conv2d-224          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-225          [-1, 256, 32, 32]             512\n",
            "            ReLU-226          [-1, 256, 32, 32]               0\n",
            "          Conv2d-227         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-228         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-229         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-230         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-231          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-232          [-1, 256, 32, 32]             512\n",
            "            ReLU-233          [-1, 256, 32, 32]               0\n",
            "          Conv2d-234          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-235          [-1, 256, 32, 32]             512\n",
            "            ReLU-236          [-1, 256, 32, 32]               0\n",
            "          Conv2d-237         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-238         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-239         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-240         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-241          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-242          [-1, 256, 32, 32]             512\n",
            "            ReLU-243          [-1, 256, 32, 32]               0\n",
            "          Conv2d-244          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-245          [-1, 256, 32, 32]             512\n",
            "            ReLU-246          [-1, 256, 32, 32]               0\n",
            "          Conv2d-247         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-248         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-249         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-250         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-251          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-252          [-1, 256, 32, 32]             512\n",
            "            ReLU-253          [-1, 256, 32, 32]               0\n",
            "          Conv2d-254          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-255          [-1, 256, 32, 32]             512\n",
            "            ReLU-256          [-1, 256, 32, 32]               0\n",
            "          Conv2d-257         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-258         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-259         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-260         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-261          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-262          [-1, 256, 32, 32]             512\n",
            "            ReLU-263          [-1, 256, 32, 32]               0\n",
            "          Conv2d-264          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-265          [-1, 256, 32, 32]             512\n",
            "            ReLU-266          [-1, 256, 32, 32]               0\n",
            "          Conv2d-267         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-268         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-269         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-270         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-271          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-272          [-1, 256, 32, 32]             512\n",
            "            ReLU-273          [-1, 256, 32, 32]               0\n",
            "          Conv2d-274          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-275          [-1, 256, 32, 32]             512\n",
            "            ReLU-276          [-1, 256, 32, 32]               0\n",
            "          Conv2d-277         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-278         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-279         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-280         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-281          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-282          [-1, 256, 32, 32]             512\n",
            "            ReLU-283          [-1, 256, 32, 32]               0\n",
            "          Conv2d-284          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-285          [-1, 256, 32, 32]             512\n",
            "            ReLU-286          [-1, 256, 32, 32]               0\n",
            "          Conv2d-287         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-288         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-289         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-290         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-291          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-292          [-1, 256, 32, 32]             512\n",
            "            ReLU-293          [-1, 256, 32, 32]               0\n",
            "          Conv2d-294          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-295          [-1, 256, 32, 32]             512\n",
            "            ReLU-296          [-1, 256, 32, 32]               0\n",
            "          Conv2d-297         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-298         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-299         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-300         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-301          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-302          [-1, 256, 32, 32]             512\n",
            "            ReLU-303          [-1, 256, 32, 32]               0\n",
            "          Conv2d-304          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-305          [-1, 256, 32, 32]             512\n",
            "            ReLU-306          [-1, 256, 32, 32]               0\n",
            "          Conv2d-307         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-308         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-309         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-310         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-311          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-312          [-1, 256, 32, 32]             512\n",
            "            ReLU-313          [-1, 256, 32, 32]               0\n",
            "          Conv2d-314          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-315          [-1, 256, 32, 32]             512\n",
            "            ReLU-316          [-1, 256, 32, 32]               0\n",
            "          Conv2d-317         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-318         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-319         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-320         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-321          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-322          [-1, 256, 32, 32]             512\n",
            "            ReLU-323          [-1, 256, 32, 32]               0\n",
            "          Conv2d-324          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-325          [-1, 256, 32, 32]             512\n",
            "            ReLU-326          [-1, 256, 32, 32]               0\n",
            "          Conv2d-327         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-328         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-329         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-330         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-331          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-332          [-1, 256, 32, 32]             512\n",
            "            ReLU-333          [-1, 256, 32, 32]               0\n",
            "          Conv2d-334          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-335          [-1, 256, 32, 32]             512\n",
            "            ReLU-336          [-1, 256, 32, 32]               0\n",
            "          Conv2d-337         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-338         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-339         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-340         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-341          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-342          [-1, 256, 32, 32]             512\n",
            "            ReLU-343          [-1, 256, 32, 32]               0\n",
            "          Conv2d-344          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-345          [-1, 256, 32, 32]             512\n",
            "            ReLU-346          [-1, 256, 32, 32]               0\n",
            "          Conv2d-347         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-348         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-349         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-350         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-351          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-352          [-1, 256, 32, 32]             512\n",
            "            ReLU-353          [-1, 256, 32, 32]               0\n",
            "          Conv2d-354          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-355          [-1, 256, 32, 32]             512\n",
            "            ReLU-356          [-1, 256, 32, 32]               0\n",
            "          Conv2d-357         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-358         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-359         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-360         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-361          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-362          [-1, 256, 32, 32]             512\n",
            "            ReLU-363          [-1, 256, 32, 32]               0\n",
            "          Conv2d-364          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-365          [-1, 256, 32, 32]             512\n",
            "            ReLU-366          [-1, 256, 32, 32]               0\n",
            "          Conv2d-367         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-368         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-369         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-370         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-371          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-372          [-1, 256, 32, 32]             512\n",
            "            ReLU-373          [-1, 256, 32, 32]               0\n",
            "          Conv2d-374          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-375          [-1, 256, 32, 32]             512\n",
            "            ReLU-376          [-1, 256, 32, 32]               0\n",
            "          Conv2d-377         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-378         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-379         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-380         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-381          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-382          [-1, 256, 32, 32]             512\n",
            "            ReLU-383          [-1, 256, 32, 32]               0\n",
            "          Conv2d-384          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-385          [-1, 256, 32, 32]             512\n",
            "            ReLU-386          [-1, 256, 32, 32]               0\n",
            "          Conv2d-387         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-388         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-389         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-390         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-391          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-392          [-1, 256, 32, 32]             512\n",
            "            ReLU-393          [-1, 256, 32, 32]               0\n",
            "          Conv2d-394          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-395          [-1, 256, 32, 32]             512\n",
            "            ReLU-396          [-1, 256, 32, 32]               0\n",
            "          Conv2d-397         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-398         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-399         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-400         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-401          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-402          [-1, 256, 32, 32]             512\n",
            "            ReLU-403          [-1, 256, 32, 32]               0\n",
            "          Conv2d-404          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-405          [-1, 256, 32, 32]             512\n",
            "            ReLU-406          [-1, 256, 32, 32]               0\n",
            "          Conv2d-407         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-408         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-409         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-410         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-411          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-412          [-1, 256, 32, 32]             512\n",
            "            ReLU-413          [-1, 256, 32, 32]               0\n",
            "          Conv2d-414          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-415          [-1, 256, 32, 32]             512\n",
            "            ReLU-416          [-1, 256, 32, 32]               0\n",
            "          Conv2d-417         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-418         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-419         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-420         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-421          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-422          [-1, 256, 32, 32]             512\n",
            "            ReLU-423          [-1, 256, 32, 32]               0\n",
            "          Conv2d-424          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-425          [-1, 256, 32, 32]             512\n",
            "            ReLU-426          [-1, 256, 32, 32]               0\n",
            "          Conv2d-427         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-428         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-429         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-430         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-431          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-432          [-1, 256, 32, 32]             512\n",
            "            ReLU-433          [-1, 256, 32, 32]               0\n",
            "          Conv2d-434          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-435          [-1, 256, 32, 32]             512\n",
            "            ReLU-436          [-1, 256, 32, 32]               0\n",
            "          Conv2d-437         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-438         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-439         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-440         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-441          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-442          [-1, 256, 32, 32]             512\n",
            "            ReLU-443          [-1, 256, 32, 32]               0\n",
            "          Conv2d-444          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-445          [-1, 256, 32, 32]             512\n",
            "            ReLU-446          [-1, 256, 32, 32]               0\n",
            "          Conv2d-447         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-448         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-449         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-450         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-451          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-452          [-1, 256, 32, 32]             512\n",
            "            ReLU-453          [-1, 256, 32, 32]               0\n",
            "          Conv2d-454          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-455          [-1, 256, 32, 32]             512\n",
            "            ReLU-456          [-1, 256, 32, 32]               0\n",
            "          Conv2d-457         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-458         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-459         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-460         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-461          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-462          [-1, 256, 32, 32]             512\n",
            "            ReLU-463          [-1, 256, 32, 32]               0\n",
            "          Conv2d-464          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-465          [-1, 256, 32, 32]             512\n",
            "            ReLU-466          [-1, 256, 32, 32]               0\n",
            "          Conv2d-467         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-468         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-469         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-470         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-471          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-472          [-1, 256, 32, 32]             512\n",
            "            ReLU-473          [-1, 256, 32, 32]               0\n",
            "          Conv2d-474          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-475          [-1, 256, 32, 32]             512\n",
            "            ReLU-476          [-1, 256, 32, 32]               0\n",
            "          Conv2d-477         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-478         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-479         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-480         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-481          [-1, 512, 32, 32]         524,288\n",
            "     BatchNorm2d-482          [-1, 512, 32, 32]           1,024\n",
            "            ReLU-483          [-1, 512, 32, 32]               0\n",
            "          Conv2d-484          [-1, 512, 16, 16]       2,359,296\n",
            "     BatchNorm2d-485          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-486          [-1, 512, 16, 16]               0\n",
            "          Conv2d-487         [-1, 2048, 16, 16]       1,048,576\n",
            "     BatchNorm2d-488         [-1, 2048, 16, 16]           4,096\n",
            "          Conv2d-489         [-1, 2048, 16, 16]       2,097,152\n",
            "     BatchNorm2d-490         [-1, 2048, 16, 16]           4,096\n",
            "            ReLU-491         [-1, 2048, 16, 16]               0\n",
            "      Bottleneck-492         [-1, 2048, 16, 16]               0\n",
            "          Conv2d-493          [-1, 512, 16, 16]       1,048,576\n",
            "     BatchNorm2d-494          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-495          [-1, 512, 16, 16]               0\n",
            "          Conv2d-496          [-1, 512, 16, 16]       2,359,296\n",
            "     BatchNorm2d-497          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-498          [-1, 512, 16, 16]               0\n",
            "          Conv2d-499         [-1, 2048, 16, 16]       1,048,576\n",
            "     BatchNorm2d-500         [-1, 2048, 16, 16]           4,096\n",
            "            ReLU-501         [-1, 2048, 16, 16]               0\n",
            "      Bottleneck-502         [-1, 2048, 16, 16]               0\n",
            "          Conv2d-503          [-1, 512, 16, 16]       1,048,576\n",
            "     BatchNorm2d-504          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-505          [-1, 512, 16, 16]               0\n",
            "          Conv2d-506          [-1, 512, 16, 16]       2,359,296\n",
            "     BatchNorm2d-507          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-508          [-1, 512, 16, 16]               0\n",
            "          Conv2d-509         [-1, 2048, 16, 16]       1,048,576\n",
            "     BatchNorm2d-510         [-1, 2048, 16, 16]           4,096\n",
            "            ReLU-511         [-1, 2048, 16, 16]               0\n",
            "      Bottleneck-512         [-1, 2048, 16, 16]               0\n",
            "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
            "         Flatten-514                 [-1, 2048]               0\n",
            "SelectAdaptivePool2d-515                 [-1, 2048]               0\n",
            "          Linear-516                   [-1, 14]          28,686\n",
            "================================================================\n",
            "Total params: 58,166,222\n",
            "Trainable params: 58,166,222\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.00\n",
            "Forward/backward pass size (MB): 3169.05\n",
            "Params size (MB): 221.89\n",
            "Estimated Total Size (MB): 3391.93\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model.to('cuda'),(1,512,512))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GPv8m22FaN3"
      },
      "outputs": [],
      "source": [
        "model_ft = model.to(device)\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(),lr=0.001)# 업데이트 할 파라미터만 넣어준다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_idx= np.array(list(class2idx.values())).reshape(-1,1)\n",
        "np.unique(label_idx)\n",
        "\n",
        "labels=labeling_df['Finding Labels']\n",
        "labels.replace(class2idx,inplace = True)\n",
        "\n",
        "label_array=labels.values\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "loss_weight = compute_class_weight(class_weight = 'balanced', classes = np.unique(label_idx) ,y = label_array)\n",
        "weighted_loss= torch.FloatTensor(loss_weight).to(device)"
      ],
      "metadata": {
        "id": "QD6TVeaWCFTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utH7pN1VD-rX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533c273b-e741-4116-94a9-930dce978c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 2.4402 Acc: 0.3079,f1 :0.1189,Time : 2481.6404\n",
            "val Loss: 2.7245 Acc: 0.3045,f1 :0.1172,Time : 221.7262\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 2.4035 Acc: 0.2985,f1 :0.1141,Time : 2461.6666\n",
            "val Loss: 2.3782 Acc: 0.2845,f1 :0.1088,Time : 213.4615\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 2.3815 Acc: 0.2905,f1 :0.1112,Time : 2461.3899\n",
            "val Loss: 2.3665 Acc: 0.2973,f1 :0.1136,Time : 214.2010\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 2.3505 Acc: 0.2931,f1 :0.1122,Time : 2470.0493\n",
            "val Loss: 2.3856 Acc: 0.2842,f1 :0.1084,Time : 216.4871\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 2.3293 Acc: 0.2987,f1 :0.1143,Time : 2455.4355\n",
            "val Loss: 2.3571 Acc: 0.2887,f1 :0.1102,Time : 212.2634\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 2.3011 Acc: 0.3108,f1 :0.1193,Time : 2447.7060\n",
            "val Loss: 2.2998 Acc: 0.3118,f1 :0.1201,Time : 211.8079\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 2.2749 Acc: 0.3187,f1 :0.1237,Time : 2448.6514\n",
            "val Loss: 2.2726 Acc: 0.3149,f1 :0.1221,Time : 212.3221\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 2.2476 Acc: 0.3245,f1 :0.1255,Time : 2447.5151\n",
            "val Loss: 2.2655 Acc: 0.3171,f1 :0.1226,Time : 212.3264\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 2.2216 Acc: 0.3301,f1 :0.1284,Time : 2436.1108\n",
            "val Loss: 2.2409 Acc: 0.3273,f1 :0.1276,Time : 208.9496\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 2.1890 Acc: 0.3377,f1 :0.1322,Time : 2430.6341\n",
            "val Loss: 2.2406 Acc: 0.3299,f1 :0.1287,Time : 210.0164\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 2.1673 Acc: 0.3478,f1 :0.1360,Time : 2435.0368\n",
            "val Loss: 2.1962 Acc: 0.3578,f1 :0.1408,Time : 208.9943\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 2.1390 Acc: 0.3532,f1 :0.1384,Time : 2439.8258\n",
            "val Loss: 2.2438 Acc: 0.3078,f1 :0.1180,Time : 210.4407\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 2.1136 Acc: 0.3596,f1 :0.1411,Time : 2439.9710\n",
            "val Loss: 2.2208 Acc: 0.3465,f1 :0.1352,Time : 210.5086\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 2.0854 Acc: 0.3666,f1 :0.1449,Time : 2444.2077\n",
            "val Loss: 2.2149 Acc: 0.3612,f1 :0.1423,Time : 211.0245\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 2.0632 Acc: 0.3704,f1 :0.1463,Time : 2444.2050\n",
            "val Loss: 2.1724 Acc: 0.3420,f1 :0.1325,Time : 210.3395\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 2.0379 Acc: 0.3778,f1 :0.1497,Time : 2452.2144\n",
            "val Loss: 2.1666 Acc: 0.3477,f1 :0.1353,Time : 210.7567\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 2.0002 Acc: 0.3832,f1 :0.1521,Time : 2443.2689\n",
            "val Loss: 2.1908 Acc: 0.3302,f1 :0.1275,Time : 211.1103\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 1.9642 Acc: 0.3966,f1 :0.1587,Time : 2442.3166\n",
            "val Loss: 2.2069 Acc: 0.3588,f1 :0.1421,Time : 210.6168\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 1.9303 Acc: 0.4015,f1 :0.1614,Time : 2439.4441\n",
            "val Loss: 2.2528 Acc: 0.3221,f1 :0.1249,Time : 210.2816\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 1.8842 Acc: 0.4144,f1 :0.1667,Time : 2445.8810\n",
            "val Loss: 2.2234 Acc: 0.3276,f1 :0.1282,Time : 214.8100\n",
            "Training complete in 886m 50s\n",
            "Best val Acc: 0.361214\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss(weighted_loss)\n",
        "# Train and evaluate\n",
        "model_ft, train_dict, val_dict  = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gahod6pFM21C"
      },
      "outputs": [],
      "source": [
        "torch.save(model_ft, '/content/drive/Shareddrives/캡스톤 디자인1/codes/resnet151_multiclassclassfication_nofinding_제외_timm_loss_weight')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dict['f1']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nTip1V8kdCe",
        "outputId": "506b9817-82cb-4cc9-e168-3cf959aae3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11885345175616206,\n",
              " 0.11407616740681342,\n",
              " 0.11119633965819248,\n",
              " 0.1122459965011476,\n",
              " 0.11430493877002136,\n",
              " 0.11933790876060264,\n",
              " 0.12367110752254701,\n",
              " 0.1254743641501891,\n",
              " 0.1283541918988095,\n",
              " 0.1322163907953249,\n",
              " 0.13595747544073072,\n",
              " 0.13836630332392313,\n",
              " 0.14109810254340974,\n",
              " 0.1449333871619003,\n",
              " 0.14630601534114943,\n",
              " 0.14968375723322447,\n",
              " 0.15210604225542884,\n",
              " 0.1587000403714303,\n",
              " 0.16143183959091667,\n",
              " 0.1667339523617415]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "d3jRBkZRkdHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_dict['Loss'])):\n",
        "  train_loss.append(train_dict['Loss'][i])\n",
        "for i in range(len(val_dict['Loss'])):\n",
        "  val_loss.append(val_dict['Loss'][i])"
      ],
      "metadata": {
        "id": "dPWOxovwkxf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdgUEYt0HQjE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "9201df4d-fd6f-4d1b-fcb4-58b2f32f65e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.title('Resnet152 Loss', fontsize = 15)\n",
        "plt.xlabel('Epoch', fontsize = 15)\n",
        "plt.ylabel('Loss', fontsize = 15)\n",
        "plt.ylim(0,4)\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWj469HeMans"
      },
      "outputs": [],
      "source": [
        "train_accuracy = []\n",
        "val_accuracy = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCgIB62sO8x8"
      },
      "outputs": [],
      "source": [
        "for i in range(len(train_dict['Accuarcy'])):\n",
        "  train_accuracy.append(train_dict['Accuarcy'][i].to('cpu').numpy())\n",
        "for i in range(len(val_dict['Accuarcy'])):\n",
        "  val_accuracy.append(val_dict['Accuarcy'][i].to('cpu').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTJpCyCMQj6-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "1b79f9b5-0d40-4a36-fc2b-6ddbcb3fc465"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(train_accuracy)\n",
        "plt.plot(val_accuracy)\n",
        "plt.title('Resnet152 Accuracy', fontsize = 15)\n",
        "plt.xlabel('Epoch', fontsize = 15)\n",
        "plt.ylabel('Accuracy', fontsize = 15)\n",
        "plt.ylim(0,1)\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1 = []\n",
        "val_f1 = []"
      ],
      "metadata": {
        "id": "5bYu3ku3nq0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_dict['f1'])):\n",
        "  train_loss.append(train_dict['f1'][i])\n",
        "for i in range(len(val_dict['f1'])):\n",
        "  val_loss.append(val_dict['f1'][i])"
      ],
      "metadata": {
        "id": "Fc5cxuzqnqCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee4qZ887MHeI"
      },
      "outputs": [],
      "source": [
        "train_acc[0].to('cpu').numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJo_jNbrMzO3"
      },
      "outputs": [],
      "source": [
        "train_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvU7IXQTWbt7"
      },
      "outputs": [],
      "source": [
        "model_ft = torch.load('/content/drive/Shareddrives/캡스톤 디자인1/codes/resnet151_multiclassclassfication_nofinding_제외_timm_loss_weight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8GGBWFXJ0Wu"
      },
      "outputs": [],
      "source": [
        "model_ft = model_ft.to(device)\n",
        "\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(),lr=0.001)# 업데이트 할 파라미터만 넣어준다.\n",
        "class test_Dataset(Dataset):\n",
        "    def __init__(self, data_path,transform = None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data_path)\n",
        "    def __getitem__(self,idx):\n",
        "        path = self.data_path[idx]\n",
        "        img = np.array(Image.open(path))\n",
        "        img = img[:,:,np.newaxis]\n",
        "        img = img/255\n",
        "        label =  class2idx[df[df['Image Index']== path.split('/')[-1]]['Finding Labels'].values[0]]\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=img)\n",
        "            image = transformed['image']\n",
        "        return image.float(), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28Y0MRroJ1Mj"
      },
      "outputs": [],
      "source": [
        "data_transforms_test = A.Compose(\n",
        "        [\n",
        "     ToTensorV2()\n",
        "     ]\n",
        "     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gChfEB7KJ-n8"
      },
      "outputs": [],
      "source": [
        "test_data = test_Dataset(val_path,transform = data_transforms_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X74UDNdohkwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af775127-27ff-4609-d867-a89ec1dece05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]           3,136\n",
            "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
            "              ReLU-3         [-1, 64, 256, 256]               0\n",
            "         MaxPool2d-4         [-1, 64, 128, 128]               0\n",
            "            Conv2d-5         [-1, 64, 128, 128]           4,096\n",
            "       BatchNorm2d-6         [-1, 64, 128, 128]             128\n",
            "              ReLU-7         [-1, 64, 128, 128]               0\n",
            "            Conv2d-8         [-1, 64, 128, 128]          36,864\n",
            "       BatchNorm2d-9         [-1, 64, 128, 128]             128\n",
            "             ReLU-10         [-1, 64, 128, 128]               0\n",
            "           Conv2d-11        [-1, 256, 128, 128]          16,384\n",
            "      BatchNorm2d-12        [-1, 256, 128, 128]             512\n",
            "           Conv2d-13        [-1, 256, 128, 128]          16,384\n",
            "      BatchNorm2d-14        [-1, 256, 128, 128]             512\n",
            "             ReLU-15        [-1, 256, 128, 128]               0\n",
            "       Bottleneck-16        [-1, 256, 128, 128]               0\n",
            "           Conv2d-17         [-1, 64, 128, 128]          16,384\n",
            "      BatchNorm2d-18         [-1, 64, 128, 128]             128\n",
            "             ReLU-19         [-1, 64, 128, 128]               0\n",
            "           Conv2d-20         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-21         [-1, 64, 128, 128]             128\n",
            "             ReLU-22         [-1, 64, 128, 128]               0\n",
            "           Conv2d-23        [-1, 256, 128, 128]          16,384\n",
            "      BatchNorm2d-24        [-1, 256, 128, 128]             512\n",
            "             ReLU-25        [-1, 256, 128, 128]               0\n",
            "       Bottleneck-26        [-1, 256, 128, 128]               0\n",
            "           Conv2d-27         [-1, 64, 128, 128]          16,384\n",
            "      BatchNorm2d-28         [-1, 64, 128, 128]             128\n",
            "             ReLU-29         [-1, 64, 128, 128]               0\n",
            "           Conv2d-30         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-31         [-1, 64, 128, 128]             128\n",
            "             ReLU-32         [-1, 64, 128, 128]               0\n",
            "           Conv2d-33        [-1, 256, 128, 128]          16,384\n",
            "      BatchNorm2d-34        [-1, 256, 128, 128]             512\n",
            "             ReLU-35        [-1, 256, 128, 128]               0\n",
            "       Bottleneck-36        [-1, 256, 128, 128]               0\n",
            "           Conv2d-37        [-1, 128, 128, 128]          32,768\n",
            "      BatchNorm2d-38        [-1, 128, 128, 128]             256\n",
            "             ReLU-39        [-1, 128, 128, 128]               0\n",
            "           Conv2d-40          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 64, 64]             256\n",
            "             ReLU-42          [-1, 128, 64, 64]               0\n",
            "           Conv2d-43          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 64, 64]           1,024\n",
            "           Conv2d-45          [-1, 512, 64, 64]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-47          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-48          [-1, 512, 64, 64]               0\n",
            "           Conv2d-49          [-1, 128, 64, 64]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 64, 64]             256\n",
            "             ReLU-51          [-1, 128, 64, 64]               0\n",
            "           Conv2d-52          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 64, 64]             256\n",
            "             ReLU-54          [-1, 128, 64, 64]               0\n",
            "           Conv2d-55          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-57          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-58          [-1, 512, 64, 64]               0\n",
            "           Conv2d-59          [-1, 128, 64, 64]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 64, 64]             256\n",
            "             ReLU-61          [-1, 128, 64, 64]               0\n",
            "           Conv2d-62          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 64, 64]             256\n",
            "             ReLU-64          [-1, 128, 64, 64]               0\n",
            "           Conv2d-65          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-67          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-68          [-1, 512, 64, 64]               0\n",
            "           Conv2d-69          [-1, 128, 64, 64]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 64, 64]             256\n",
            "             ReLU-71          [-1, 128, 64, 64]               0\n",
            "           Conv2d-72          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 64, 64]             256\n",
            "             ReLU-74          [-1, 128, 64, 64]               0\n",
            "           Conv2d-75          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-77          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-78          [-1, 512, 64, 64]               0\n",
            "           Conv2d-79          [-1, 128, 64, 64]          65,536\n",
            "      BatchNorm2d-80          [-1, 128, 64, 64]             256\n",
            "             ReLU-81          [-1, 128, 64, 64]               0\n",
            "           Conv2d-82          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-83          [-1, 128, 64, 64]             256\n",
            "             ReLU-84          [-1, 128, 64, 64]               0\n",
            "           Conv2d-85          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-86          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-87          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-88          [-1, 512, 64, 64]               0\n",
            "           Conv2d-89          [-1, 128, 64, 64]          65,536\n",
            "      BatchNorm2d-90          [-1, 128, 64, 64]             256\n",
            "             ReLU-91          [-1, 128, 64, 64]               0\n",
            "           Conv2d-92          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-93          [-1, 128, 64, 64]             256\n",
            "             ReLU-94          [-1, 128, 64, 64]               0\n",
            "           Conv2d-95          [-1, 512, 64, 64]          65,536\n",
            "      BatchNorm2d-96          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-97          [-1, 512, 64, 64]               0\n",
            "       Bottleneck-98          [-1, 512, 64, 64]               0\n",
            "           Conv2d-99          [-1, 128, 64, 64]          65,536\n",
            "     BatchNorm2d-100          [-1, 128, 64, 64]             256\n",
            "            ReLU-101          [-1, 128, 64, 64]               0\n",
            "          Conv2d-102          [-1, 128, 64, 64]         147,456\n",
            "     BatchNorm2d-103          [-1, 128, 64, 64]             256\n",
            "            ReLU-104          [-1, 128, 64, 64]               0\n",
            "          Conv2d-105          [-1, 512, 64, 64]          65,536\n",
            "     BatchNorm2d-106          [-1, 512, 64, 64]           1,024\n",
            "            ReLU-107          [-1, 512, 64, 64]               0\n",
            "      Bottleneck-108          [-1, 512, 64, 64]               0\n",
            "          Conv2d-109          [-1, 128, 64, 64]          65,536\n",
            "     BatchNorm2d-110          [-1, 128, 64, 64]             256\n",
            "            ReLU-111          [-1, 128, 64, 64]               0\n",
            "          Conv2d-112          [-1, 128, 64, 64]         147,456\n",
            "     BatchNorm2d-113          [-1, 128, 64, 64]             256\n",
            "            ReLU-114          [-1, 128, 64, 64]               0\n",
            "          Conv2d-115          [-1, 512, 64, 64]          65,536\n",
            "     BatchNorm2d-116          [-1, 512, 64, 64]           1,024\n",
            "            ReLU-117          [-1, 512, 64, 64]               0\n",
            "      Bottleneck-118          [-1, 512, 64, 64]               0\n",
            "          Conv2d-119          [-1, 256, 64, 64]         131,072\n",
            "     BatchNorm2d-120          [-1, 256, 64, 64]             512\n",
            "            ReLU-121          [-1, 256, 64, 64]               0\n",
            "          Conv2d-122          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-123          [-1, 256, 32, 32]             512\n",
            "            ReLU-124          [-1, 256, 32, 32]               0\n",
            "          Conv2d-125         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-126         [-1, 1024, 32, 32]           2,048\n",
            "          Conv2d-127         [-1, 1024, 32, 32]         524,288\n",
            "     BatchNorm2d-128         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-129         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-130         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-131          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 32, 32]             512\n",
            "            ReLU-133          [-1, 256, 32, 32]               0\n",
            "          Conv2d-134          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 32, 32]             512\n",
            "            ReLU-136          [-1, 256, 32, 32]               0\n",
            "          Conv2d-137         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-139         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-140         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-141          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-142          [-1, 256, 32, 32]             512\n",
            "            ReLU-143          [-1, 256, 32, 32]               0\n",
            "          Conv2d-144          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-145          [-1, 256, 32, 32]             512\n",
            "            ReLU-146          [-1, 256, 32, 32]               0\n",
            "          Conv2d-147         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-148         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-149         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-150         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-151          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-152          [-1, 256, 32, 32]             512\n",
            "            ReLU-153          [-1, 256, 32, 32]               0\n",
            "          Conv2d-154          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-155          [-1, 256, 32, 32]             512\n",
            "            ReLU-156          [-1, 256, 32, 32]               0\n",
            "          Conv2d-157         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-158         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-159         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-160         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-161          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-162          [-1, 256, 32, 32]             512\n",
            "            ReLU-163          [-1, 256, 32, 32]               0\n",
            "          Conv2d-164          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-165          [-1, 256, 32, 32]             512\n",
            "            ReLU-166          [-1, 256, 32, 32]               0\n",
            "          Conv2d-167         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-168         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-169         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-170         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-171          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-172          [-1, 256, 32, 32]             512\n",
            "            ReLU-173          [-1, 256, 32, 32]               0\n",
            "          Conv2d-174          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-175          [-1, 256, 32, 32]             512\n",
            "            ReLU-176          [-1, 256, 32, 32]               0\n",
            "          Conv2d-177         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-178         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-179         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-180         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-181          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-182          [-1, 256, 32, 32]             512\n",
            "            ReLU-183          [-1, 256, 32, 32]               0\n",
            "          Conv2d-184          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-185          [-1, 256, 32, 32]             512\n",
            "            ReLU-186          [-1, 256, 32, 32]               0\n",
            "          Conv2d-187         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-188         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-189         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-190         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-191          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-192          [-1, 256, 32, 32]             512\n",
            "            ReLU-193          [-1, 256, 32, 32]               0\n",
            "          Conv2d-194          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-195          [-1, 256, 32, 32]             512\n",
            "            ReLU-196          [-1, 256, 32, 32]               0\n",
            "          Conv2d-197         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-198         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-199         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-200         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-201          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-202          [-1, 256, 32, 32]             512\n",
            "            ReLU-203          [-1, 256, 32, 32]               0\n",
            "          Conv2d-204          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-205          [-1, 256, 32, 32]             512\n",
            "            ReLU-206          [-1, 256, 32, 32]               0\n",
            "          Conv2d-207         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-208         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-209         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-210         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-211          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-212          [-1, 256, 32, 32]             512\n",
            "            ReLU-213          [-1, 256, 32, 32]               0\n",
            "          Conv2d-214          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-215          [-1, 256, 32, 32]             512\n",
            "            ReLU-216          [-1, 256, 32, 32]               0\n",
            "          Conv2d-217         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-218         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-219         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-220         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-221          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-222          [-1, 256, 32, 32]             512\n",
            "            ReLU-223          [-1, 256, 32, 32]               0\n",
            "          Conv2d-224          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-225          [-1, 256, 32, 32]             512\n",
            "            ReLU-226          [-1, 256, 32, 32]               0\n",
            "          Conv2d-227         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-228         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-229         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-230         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-231          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-232          [-1, 256, 32, 32]             512\n",
            "            ReLU-233          [-1, 256, 32, 32]               0\n",
            "          Conv2d-234          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-235          [-1, 256, 32, 32]             512\n",
            "            ReLU-236          [-1, 256, 32, 32]               0\n",
            "          Conv2d-237         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-238         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-239         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-240         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-241          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-242          [-1, 256, 32, 32]             512\n",
            "            ReLU-243          [-1, 256, 32, 32]               0\n",
            "          Conv2d-244          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-245          [-1, 256, 32, 32]             512\n",
            "            ReLU-246          [-1, 256, 32, 32]               0\n",
            "          Conv2d-247         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-248         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-249         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-250         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-251          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-252          [-1, 256, 32, 32]             512\n",
            "            ReLU-253          [-1, 256, 32, 32]               0\n",
            "          Conv2d-254          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-255          [-1, 256, 32, 32]             512\n",
            "            ReLU-256          [-1, 256, 32, 32]               0\n",
            "          Conv2d-257         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-258         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-259         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-260         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-261          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-262          [-1, 256, 32, 32]             512\n",
            "            ReLU-263          [-1, 256, 32, 32]               0\n",
            "          Conv2d-264          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-265          [-1, 256, 32, 32]             512\n",
            "            ReLU-266          [-1, 256, 32, 32]               0\n",
            "          Conv2d-267         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-268         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-269         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-270         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-271          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-272          [-1, 256, 32, 32]             512\n",
            "            ReLU-273          [-1, 256, 32, 32]               0\n",
            "          Conv2d-274          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-275          [-1, 256, 32, 32]             512\n",
            "            ReLU-276          [-1, 256, 32, 32]               0\n",
            "          Conv2d-277         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-278         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-279         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-280         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-281          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-282          [-1, 256, 32, 32]             512\n",
            "            ReLU-283          [-1, 256, 32, 32]               0\n",
            "          Conv2d-284          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-285          [-1, 256, 32, 32]             512\n",
            "            ReLU-286          [-1, 256, 32, 32]               0\n",
            "          Conv2d-287         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-288         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-289         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-290         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-291          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-292          [-1, 256, 32, 32]             512\n",
            "            ReLU-293          [-1, 256, 32, 32]               0\n",
            "          Conv2d-294          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-295          [-1, 256, 32, 32]             512\n",
            "            ReLU-296          [-1, 256, 32, 32]               0\n",
            "          Conv2d-297         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-298         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-299         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-300         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-301          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-302          [-1, 256, 32, 32]             512\n",
            "            ReLU-303          [-1, 256, 32, 32]               0\n",
            "          Conv2d-304          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-305          [-1, 256, 32, 32]             512\n",
            "            ReLU-306          [-1, 256, 32, 32]               0\n",
            "          Conv2d-307         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-308         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-309         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-310         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-311          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-312          [-1, 256, 32, 32]             512\n",
            "            ReLU-313          [-1, 256, 32, 32]               0\n",
            "          Conv2d-314          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-315          [-1, 256, 32, 32]             512\n",
            "            ReLU-316          [-1, 256, 32, 32]               0\n",
            "          Conv2d-317         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-318         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-319         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-320         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-321          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-322          [-1, 256, 32, 32]             512\n",
            "            ReLU-323          [-1, 256, 32, 32]               0\n",
            "          Conv2d-324          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-325          [-1, 256, 32, 32]             512\n",
            "            ReLU-326          [-1, 256, 32, 32]               0\n",
            "          Conv2d-327         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-328         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-329         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-330         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-331          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-332          [-1, 256, 32, 32]             512\n",
            "            ReLU-333          [-1, 256, 32, 32]               0\n",
            "          Conv2d-334          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-335          [-1, 256, 32, 32]             512\n",
            "            ReLU-336          [-1, 256, 32, 32]               0\n",
            "          Conv2d-337         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-338         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-339         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-340         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-341          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-342          [-1, 256, 32, 32]             512\n",
            "            ReLU-343          [-1, 256, 32, 32]               0\n",
            "          Conv2d-344          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-345          [-1, 256, 32, 32]             512\n",
            "            ReLU-346          [-1, 256, 32, 32]               0\n",
            "          Conv2d-347         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-348         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-349         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-350         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-351          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-352          [-1, 256, 32, 32]             512\n",
            "            ReLU-353          [-1, 256, 32, 32]               0\n",
            "          Conv2d-354          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-355          [-1, 256, 32, 32]             512\n",
            "            ReLU-356          [-1, 256, 32, 32]               0\n",
            "          Conv2d-357         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-358         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-359         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-360         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-361          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-362          [-1, 256, 32, 32]             512\n",
            "            ReLU-363          [-1, 256, 32, 32]               0\n",
            "          Conv2d-364          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-365          [-1, 256, 32, 32]             512\n",
            "            ReLU-366          [-1, 256, 32, 32]               0\n",
            "          Conv2d-367         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-368         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-369         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-370         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-371          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-372          [-1, 256, 32, 32]             512\n",
            "            ReLU-373          [-1, 256, 32, 32]               0\n",
            "          Conv2d-374          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-375          [-1, 256, 32, 32]             512\n",
            "            ReLU-376          [-1, 256, 32, 32]               0\n",
            "          Conv2d-377         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-378         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-379         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-380         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-381          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-382          [-1, 256, 32, 32]             512\n",
            "            ReLU-383          [-1, 256, 32, 32]               0\n",
            "          Conv2d-384          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-385          [-1, 256, 32, 32]             512\n",
            "            ReLU-386          [-1, 256, 32, 32]               0\n",
            "          Conv2d-387         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-388         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-389         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-390         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-391          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-392          [-1, 256, 32, 32]             512\n",
            "            ReLU-393          [-1, 256, 32, 32]               0\n",
            "          Conv2d-394          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-395          [-1, 256, 32, 32]             512\n",
            "            ReLU-396          [-1, 256, 32, 32]               0\n",
            "          Conv2d-397         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-398         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-399         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-400         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-401          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-402          [-1, 256, 32, 32]             512\n",
            "            ReLU-403          [-1, 256, 32, 32]               0\n",
            "          Conv2d-404          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-405          [-1, 256, 32, 32]             512\n",
            "            ReLU-406          [-1, 256, 32, 32]               0\n",
            "          Conv2d-407         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-408         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-409         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-410         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-411          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-412          [-1, 256, 32, 32]             512\n",
            "            ReLU-413          [-1, 256, 32, 32]               0\n",
            "          Conv2d-414          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-415          [-1, 256, 32, 32]             512\n",
            "            ReLU-416          [-1, 256, 32, 32]               0\n",
            "          Conv2d-417         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-418         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-419         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-420         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-421          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-422          [-1, 256, 32, 32]             512\n",
            "            ReLU-423          [-1, 256, 32, 32]               0\n",
            "          Conv2d-424          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-425          [-1, 256, 32, 32]             512\n",
            "            ReLU-426          [-1, 256, 32, 32]               0\n",
            "          Conv2d-427         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-428         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-429         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-430         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-431          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-432          [-1, 256, 32, 32]             512\n",
            "            ReLU-433          [-1, 256, 32, 32]               0\n",
            "          Conv2d-434          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-435          [-1, 256, 32, 32]             512\n",
            "            ReLU-436          [-1, 256, 32, 32]               0\n",
            "          Conv2d-437         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-438         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-439         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-440         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-441          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-442          [-1, 256, 32, 32]             512\n",
            "            ReLU-443          [-1, 256, 32, 32]               0\n",
            "          Conv2d-444          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-445          [-1, 256, 32, 32]             512\n",
            "            ReLU-446          [-1, 256, 32, 32]               0\n",
            "          Conv2d-447         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-448         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-449         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-450         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-451          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-452          [-1, 256, 32, 32]             512\n",
            "            ReLU-453          [-1, 256, 32, 32]               0\n",
            "          Conv2d-454          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-455          [-1, 256, 32, 32]             512\n",
            "            ReLU-456          [-1, 256, 32, 32]               0\n",
            "          Conv2d-457         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-458         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-459         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-460         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-461          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-462          [-1, 256, 32, 32]             512\n",
            "            ReLU-463          [-1, 256, 32, 32]               0\n",
            "          Conv2d-464          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-465          [-1, 256, 32, 32]             512\n",
            "            ReLU-466          [-1, 256, 32, 32]               0\n",
            "          Conv2d-467         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-468         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-469         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-470         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-471          [-1, 256, 32, 32]         262,144\n",
            "     BatchNorm2d-472          [-1, 256, 32, 32]             512\n",
            "            ReLU-473          [-1, 256, 32, 32]               0\n",
            "          Conv2d-474          [-1, 256, 32, 32]         589,824\n",
            "     BatchNorm2d-475          [-1, 256, 32, 32]             512\n",
            "            ReLU-476          [-1, 256, 32, 32]               0\n",
            "          Conv2d-477         [-1, 1024, 32, 32]         262,144\n",
            "     BatchNorm2d-478         [-1, 1024, 32, 32]           2,048\n",
            "            ReLU-479         [-1, 1024, 32, 32]               0\n",
            "      Bottleneck-480         [-1, 1024, 32, 32]               0\n",
            "          Conv2d-481          [-1, 512, 32, 32]         524,288\n",
            "     BatchNorm2d-482          [-1, 512, 32, 32]           1,024\n",
            "            ReLU-483          [-1, 512, 32, 32]               0\n",
            "          Conv2d-484          [-1, 512, 16, 16]       2,359,296\n",
            "     BatchNorm2d-485          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-486          [-1, 512, 16, 16]               0\n",
            "          Conv2d-487         [-1, 2048, 16, 16]       1,048,576\n",
            "     BatchNorm2d-488         [-1, 2048, 16, 16]           4,096\n",
            "          Conv2d-489         [-1, 2048, 16, 16]       2,097,152\n",
            "     BatchNorm2d-490         [-1, 2048, 16, 16]           4,096\n",
            "            ReLU-491         [-1, 2048, 16, 16]               0\n",
            "      Bottleneck-492         [-1, 2048, 16, 16]               0\n",
            "          Conv2d-493          [-1, 512, 16, 16]       1,048,576\n",
            "     BatchNorm2d-494          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-495          [-1, 512, 16, 16]               0\n",
            "          Conv2d-496          [-1, 512, 16, 16]       2,359,296\n",
            "     BatchNorm2d-497          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-498          [-1, 512, 16, 16]               0\n",
            "          Conv2d-499         [-1, 2048, 16, 16]       1,048,576\n",
            "     BatchNorm2d-500         [-1, 2048, 16, 16]           4,096\n",
            "            ReLU-501         [-1, 2048, 16, 16]               0\n",
            "      Bottleneck-502         [-1, 2048, 16, 16]               0\n",
            "          Conv2d-503          [-1, 512, 16, 16]       1,048,576\n",
            "     BatchNorm2d-504          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-505          [-1, 512, 16, 16]               0\n",
            "          Conv2d-506          [-1, 512, 16, 16]       2,359,296\n",
            "     BatchNorm2d-507          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-508          [-1, 512, 16, 16]               0\n",
            "          Conv2d-509         [-1, 2048, 16, 16]       1,048,576\n",
            "     BatchNorm2d-510         [-1, 2048, 16, 16]           4,096\n",
            "            ReLU-511         [-1, 2048, 16, 16]               0\n",
            "      Bottleneck-512         [-1, 2048, 16, 16]               0\n",
            "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
            "         Flatten-514                 [-1, 2048]               0\n",
            "SelectAdaptivePool2d-515                 [-1, 2048]               0\n",
            "          Linear-516                   [-1, 14]          28,686\n",
            "================================================================\n",
            "Total params: 58,166,222\n",
            "Trainable params: 58,166,222\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.00\n",
            "Forward/backward pass size (MB): 3169.05\n",
            "Params size (MB): 221.89\n",
            "Estimated Total Size (MB): 3391.93\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model_ft.to('cuda'),(1,512,512))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97PpctyCtQCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b619a20f-187e-44ae-a6b2-070d96df6e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.0004 Acc: 0.3612, Time : 220.7027\n"
          ]
        }
      ],
      "source": [
        "running_loss = 0.0\n",
        "running_corrects = 0\n",
        "start = time.time()\n",
        "output_list = list()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    inputs = inputs.to(device = device, dtype = torch.float32)\n",
        "    labels = labels.to(device = device)\n",
        "    # zero the parameter gradients\n",
        "    optimizer_ft.zero_grad()\n",
        "    outputs = model_ft(inputs)\n",
        "    output_list+=list((torch.argmax(outputs,axis = 1).cpu().numpy()))\n",
        "    loss = criterion(outputs, labels)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    running_loss += loss.item() * inputs.size(0)\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "    epoch_loss = running_loss / len(test_loader.dataset)\n",
        "    epoch_acc = running_corrects.double() / len(test_loader.dataset)\n",
        "print('Test Loss: {:.4f} Acc: {:.4f}, Time : {:.4f}'.format(epoch_loss, epoch_acc, time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTJspyL3Y5If",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f65185-855c-414f-84e2-971114397f9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6194"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "len(test_loader)*2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcz6YIy-ucZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22322687-76c7-4422-e6c4-7217e9951aa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0rcrVsOMxjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fae0fd-7f43-4817-ff52-db18119827af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9])"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "torch.argmax(outputs,axis = 1).cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePBW5FCwMznB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fd16ab-26cb-462d-f20e-ae6bcc5154c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHIb1HFtM898"
      },
      "outputs": [],
      "source": [
        "dummy_df = pd.DataFrame(output_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLzkDU_7Dmh-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqtL3kRdN9vq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae7edfd-2432-4344-e25a-8b0e3fbc78b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8     2513\n",
              "4     1280\n",
              "0     1161\n",
              "13     374\n",
              "9      307\n",
              "1      275\n",
              "10     240\n",
              "3       24\n",
              "5       10\n",
              "2        7\n",
              "11       2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "dummy_df.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ETJnGrPOSOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b361553f-a919-49b5-827f-b4cc5bf3b3f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Infiltration          1910\n",
              "Atelectasis            843\n",
              "Effusion               791\n",
              "Nodule                 541\n",
              "Pneumothorax           439\n",
              "Mass                   428\n",
              "Consolidation          262\n",
              "Pleural_Thickening     225\n",
              "Cardiomegaly           219\n",
              "Emphysema              178\n",
              "Fibrosis               145\n",
              "Edema                  126\n",
              "Pneumonia               64\n",
              "Hernia                  22\n",
              "Name: Finding Labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "val_df['Finding Labels'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cIBEi2bdejc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986fab44-b71f-40f4-d4c4-2f89134c2cbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Atelectasis': 0,\n",
              " 'Cardiomegaly': 1,\n",
              " 'Consolidation': 2,\n",
              " 'Edema': 3,\n",
              " 'Effusion': 4,\n",
              " 'Emphysema': 5,\n",
              " 'Fibrosis': 6,\n",
              " 'Hernia': 7,\n",
              " 'Infiltration': 8,\n",
              " 'Mass': 9,\n",
              " 'Nodule': 10,\n",
              " 'Pleural_Thickening': 11,\n",
              " 'Pneumonia': 12,\n",
              " 'Pneumothorax': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "class2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb4kFbx9kmPW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "41972c8b-4545-4028-a034-a3a62c296261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 7, 7])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f29803a8410>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#레이어 시각화\n",
        "\n",
        "for w in model_ft.parameters():\n",
        "    w = w.data.cpu()\n",
        "    print(w.shape)\n",
        "    break\n",
        "\n",
        "# normalize weights\n",
        "min_w = torch.min(w)\n",
        "w1 = (-1/(2 * min_w)) * w + 0.5\n",
        "\n",
        "# make grid to display it\n",
        "grid_size = len(w1)\n",
        "x_grid = [w1[i] for i in range(grid_size)]\n",
        "x_grid = torchvision.utils.make_grid(x_grid, nrow=8, padding=1)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(x_grid.permute(2,1,0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_image = np.array(Image.open(train_path[0]))\n",
        "sample_image = sample_image[:,:,np.newaxis]/255"
      ],
      "metadata": {
        "id": "FqvQBD-muSNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6fClWdeJVOH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "sample_image = transform(sample_image)\n",
        "sample_image=sample_image.unsqueeze(0)"
      ],
      "metadata": {
        "id": "W2qqmhlxvCQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0dh0MUPvnyq",
        "outputId": "34463d6c-9a3f-407d-f28a-1afc385be4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.8196, 0.8118, 0.8078,  ..., 0.8588, 0.9020, 0.7608],\n",
              "          [0.7922, 0.7843, 0.7686,  ..., 0.8353, 0.8706, 0.7490],\n",
              "          [0.7608, 0.7490, 0.7412,  ..., 0.7922, 0.8275, 0.7176],\n",
              "          ...,\n",
              "          [0.0431, 0.0431, 0.0431,  ..., 0.0667, 0.0784, 0.0706],\n",
              "          [0.0431, 0.0431, 0.0431,  ..., 0.0667, 0.0784, 0.0706],\n",
              "          [0.0431, 0.0431, 0.0431,  ..., 0.0667, 0.0784, 0.0706]]]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1ZczPCbkm2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11f3536-23e0-4d1c-ecdb-4c3a61d60b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151\n"
          ]
        }
      ],
      "source": [
        "no_of_layers=0\n",
        "conv_layers=[]\n",
        "\n",
        "model_children=list(model_ft.children())\n",
        "\n",
        "for child in model_children:\n",
        "  if type(child)==nn.Conv2d:\n",
        "    no_of_layers+=1\n",
        "    conv_layers.append(child)\n",
        "  elif type(child)==nn.Sequential:\n",
        "    for layer in child.children():\n",
        "      for bottleneck in layer.children():\n",
        "        if type(bottleneck)==nn.Conv2d:\n",
        "          no_of_layers+=1\n",
        "          conv_layers.append(bottleneck)\n",
        "print(no_of_layers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = [conv_layers[0](sample_image.to(device = device, dtype = torch.float32))]"
      ],
      "metadata": {
        "id": "TxV4QZ7ltfTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V6LPQfN9Vfdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JLDo6IvTVh4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = [conv_layers[0](sample_image.to(device = device, dtype = torch.float32))]\n",
        "for i in range(1, len(conv_layers)):\n",
        "    results.append(conv_layers[i](results[-1]))\n",
        "outputs = results"
      ],
      "metadata": {
        "id": "4nYF08rGx4hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize 8 features map from each layer \n",
        "for num_layer in range(len(results)):\n",
        "    plt.figure(figsize=(50, 10))\n",
        "    layer_viz = results[num_layer][0, :, :, :]\n",
        "    layer_viz = layer_viz.data\n",
        "    print(\"Layer \",num_layer+1)\n",
        "    for i, filter in enumerate(layer_viz):\n",
        "        if i == 16: \n",
        "            break\n",
        "        plt.subplot(2, 8, i + 1)\n",
        "        plt.imshow(filter.cpu().numpy(), cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WmCGGt03t8oZ",
        "outputId": "a61fe85b-1cea-48c6-eb66-c152aa58f442"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wpGTWgQowGWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "resnet151_multiclassclassfication_nofinding_제외_timm_loss_weight.ipynb",
      "provenance": [],
      "mount_file_id": "1T1Wcw9de_rLioxRpyibMSuLCgbAF5i9P",
      "authorship_tag": "ABX9TyOqe3H+VRW496X/egB/pXlX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}